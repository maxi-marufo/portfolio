{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D,Conv1D\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "import tensorflow\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import collections\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.max_columns = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load \"Text+Ratings.csv\" (dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text+Ratings Length:  500001\n",
      "Text+Ratings Dtypes:\n",
      " stars    float64\n",
      "text      object\n",
      "dtype: object\n",
      "Text+Ratings Labels:  [ 4.  5.  2.  1.  3. nan]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and print info\n",
    "text_and_ratings=pd.read_csv(\"Text+Ratings.csv\",\n",
    "                            usecols=[\"text\",\"stars\"])\n",
    "print (\"Text+Ratings Length: \", len(text_and_ratings))\n",
    "print (\"Text+Ratings Dtypes:\\n\", text_and_ratings.dtypes)\n",
    "print (\"Text+Ratings Labels: \", text_and_ratings.stars.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text+Ratings Length:  500000\n",
      "Text+Ratings Dtypes:\n",
      " stars      int8\n",
      "text     object\n",
      "dtype: object\n",
      "Text+Ratings Labels:  [4 5 2 1 3]\n"
     ]
    }
   ],
   "source": [
    "# Drop NaNs and convert types\n",
    "text_and_ratings.dropna(inplace=True)\n",
    "text_and_ratings = text_and_ratings.astype({'stars': np.int8})\n",
    "print (\"Text+Ratings Length: \", len(text_and_ratings))\n",
    "print (\"Text+Ratings Dtypes:\\n\", text_and_ratings.dtypes)\n",
    "print (\"Text+Ratings Labels: \", text_and_ratings.stars.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load \"Text+Business.csv\" (dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text+Business Length:  996996\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and print info\n",
    "text_and_business=pd.read_csv(\"Text+Business.csv\",\n",
    "                            usecols=[\"text\",\"business_id\"])\n",
    "print (\"Text+Business Length: \", len(text_and_business))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text+Business Length:  996995\n"
     ]
    }
   ],
   "source": [
    "# Drop NaNs\n",
    "text_and_business.dropna(inplace=True)\n",
    "print (\"Text+Business Length: \", len(text_and_business))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4JNXUYY8wbaaDmk3BPzlWw    1308\n",
       "RESDUcs7fIiihp38-d6_6g    1278\n",
       "K7lWdNUhCbcnEvI0NhGewg    1123\n",
       "cYwJA2A6I12KNkm2rtXd5g     938\n",
       "f4x1YBxkLrZg652xt2KR5g     897\n",
       "                          ... \n",
       "ziAwyzwgQGYgJmCae042gw       1\n",
       "2KxxZnzvTP3lrtgU71tk5g       1\n",
       "v3Y3btCs-JyDR1u806otvA       1\n",
       "6BCBUPgyD7aVtMwUWdcRZA       1\n",
       "mdEkl6kDxMrg-n5s6y6Zhw       1\n",
       "Name: business_id, Length: 141627, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get some insight on its labels\n",
    "business_dist = text_and_business.business_id.value_counts()\n",
    "business_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4JNXUYY8wbaaDmk3BPzlWw    1308\n",
       "RESDUcs7fIiihp38-d6_6g    1278\n",
       "K7lWdNUhCbcnEvI0NhGewg    1123\n",
       "cYwJA2A6I12KNkm2rtXd5g     938\n",
       "f4x1YBxkLrZg652xt2KR5g     897\n",
       "                          ... \n",
       "ugLqbAvBdRDc-gS4hpslXw     305\n",
       "Xg5qEQiB-7L6kGJ5F4K3bQ     303\n",
       "yNPh5SO-7wr8HPpVCDPbXQ     301\n",
       "BIBWGO_r_1znnlmLbp4Nxg     300\n",
       "QJR4qBUHegWEozSQrGmBPw     299\n",
       "Name: business_id, Length: 100, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "yQab5dxZzgBLTEHCw9V7_w    298\n",
       "_w5hBpkjHs5_Hv3pLeHtIw    289\n",
       "L2p0vO3fsS2LC6hhQo3CzA    288\n",
       "wUKzaS1MHg94RGM6z8u9mw    286\n",
       "p0iEUamJVp_QpaheE-Nz_g    286\n",
       "                         ... \n",
       "ziAwyzwgQGYgJmCae042gw      1\n",
       "2KxxZnzvTP3lrtgU71tk5g      1\n",
       "v3Y3btCs-JyDR1u806otvA      1\n",
       "6BCBUPgyD7aVtMwUWdcRZA      1\n",
       "mdEkl6kDxMrg-n5s6y6Zhw      1\n",
       "Name: business_id, Length: 141527, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Limit number of labels\n",
    "MAX_NUMBER_BUSINESS = 100\n",
    "top_business_dist = text_and_business.business_id.value_counts()[:MAX_NUMBER_BUSINESS]\n",
    "bottom_business_dist = text_and_business.business_id.value_counts()[MAX_NUMBER_BUSINESS:]\n",
    "display(top_business_dist)\n",
    "display(bottom_business_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OTHERS                    950761\n",
       "4JNXUYY8wbaaDmk3BPzlWw      1308\n",
       "RESDUcs7fIiihp38-d6_6g      1278\n",
       "K7lWdNUhCbcnEvI0NhGewg      1123\n",
       "cYwJA2A6I12KNkm2rtXd5g       938\n",
       "                           ...  \n",
       "ugLqbAvBdRDc-gS4hpslXw       305\n",
       "Xg5qEQiB-7L6kGJ5F4K3bQ       303\n",
       "yNPh5SO-7wr8HPpVCDPbXQ       301\n",
       "BIBWGO_r_1znnlmLbp4Nxg       300\n",
       "QJR4qBUHegWEozSQrGmBPw       299\n",
       "Name: business_id, Length: 101, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relabel least frequent labels to \"OTHERS\"\n",
    "relabeled_text_and_business = text_and_business.copy()\n",
    "relabeled_text_and_business['business_id'][relabeled_text_and_business['business_id'].isin(bottom_business_dist.index)] = \"OTHERS\"\n",
    "relabeled_business_dist = relabeled_text_and_business.business_id.value_counts()\n",
    "relabeled_business_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset after drops 48850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OTHERS                    2616\n",
       "4JNXUYY8wbaaDmk3BPzlWw    1308\n",
       "RESDUcs7fIiihp38-d6_6g    1278\n",
       "K7lWdNUhCbcnEvI0NhGewg    1123\n",
       "cYwJA2A6I12KNkm2rtXd5g     938\n",
       "                          ... \n",
       "ugLqbAvBdRDc-gS4hpslXw     305\n",
       "Xg5qEQiB-7L6kGJ5F4K3bQ     303\n",
       "yNPh5SO-7wr8HPpVCDPbXQ     301\n",
       "BIBWGO_r_1znnlmLbp4Nxg     300\n",
       "QJR4qBUHegWEozSQrGmBPw     299\n",
       "Name: business_id, Length: 101, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop samples of \"OTHERS\" to make the dataset more balanced\n",
    "drop_frac = (1 - 2*float(relabeled_business_dist[1]) / relabeled_business_dist[0])\n",
    "resampled_text_and_business = relabeled_text_and_business.drop(relabeled_text_and_business[relabeled_text_and_business['business_id'] == 'OTHERS'].sample(frac=drop_frac).index)\n",
    "print(\"Length of dataset after drops\", len(resampled_text_and_business))\n",
    "resampled_text_and_business.business_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load \"Text+Rating+Business.csv\" (dataset_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text+Rating+Business Length:  5000\n",
      "Text+Rating+Business Length:  5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cYwJA2A6I12KNkm2rtXd5g    147\n",
       "KskYqH1Bi7Z_61pH6Om8pg    116\n",
       "rcaPajgKOJC2vo_l3xa42A    108\n",
       "SMPbvZLSMMb7KU76YNYMGg    107\n",
       "2weQS-RnoOBhb1KsHKyoSQ    102\n",
       "                         ... \n",
       "WbJ1LRQdOuYYlRLyTkuuxw     28\n",
       "u-SJ5QUwrNquL9VnXwl8cg     28\n",
       "gTlDDzDEHyDQ6iwjNhpI6A     28\n",
       "fHM09_y3QX3n4a_bIFbk_w     26\n",
       "pHJu8tj3sI8eC5aIHLFEfQ     24\n",
       "Name: business_id, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text+Rating+Business\n",
    "text_and_rating_and_business=pd.read_csv(\"Text+Rating+Business.csv\",\n",
    "                            usecols=[\"text\",\"stars\",\"business_id\"])\n",
    "print (\"Text+Rating+Business Length: \", len(text_and_rating_and_business))\n",
    "# Drop NaNs\n",
    "text_and_rating_and_business.dropna(inplace=True)\n",
    "print (\"Text+Rating+Business Length: \", len(text_and_rating_and_business))\n",
    "# Insight Labels\n",
    "rating_and_business_dist = text_and_rating_and_business.business_id.value_counts()\n",
    "rating_and_business_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxi/.virtualenvs/py3/lib/python3.5/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/maxi/.virtualenvs/py3/lib/python3.5/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OTHERS                    2163\n",
       "cYwJA2A6I12KNkm2rtXd5g     147\n",
       "KskYqH1Bi7Z_61pH6Om8pg     116\n",
       "rcaPajgKOJC2vo_l3xa42A     108\n",
       "SMPbvZLSMMb7KU76YNYMGg     107\n",
       "                          ... \n",
       "Fi-2ruy5x600SX4avnrFuA      47\n",
       "r_BrIgzYcwo1NAuG9dLbpg      45\n",
       "9a3DrZvpYxVs3k_qwlCNSw      43\n",
       "kRgAf6j2y1eR0wOFdzFAuw      43\n",
       "Xg5qEQiB-7L6kGJ5F4K3bQ      43\n",
       "Name: business_id, Length: 42, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Relabaling of the dataset\n",
    "relabeled_text_and_rating_and_business = text_and_rating_and_business.copy()\n",
    "# Change to OTHERS the business_id that we have not seen before\n",
    "relabeled_text_and_rating_and_business['business_id'][~relabeled_text_and_rating_and_business['business_id'].isin(business_dist.index)] = \"OTHERS\"\n",
    "# Change to OTHERS the business_id that we have seen but are from the least frequent ones\n",
    "relabeled_text_and_rating_and_business['business_id'][relabeled_text_and_rating_and_business['business_id'].isin(bottom_business_dist.index)] = \"OTHERS\"\n",
    "relabeled_text_and_rating_and_business_dist = relabeled_text_and_rating_and_business.business_id.value_counts()\n",
    "relabeled_text_and_rating_and_business_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset after drops 3131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OTHERS                    294\n",
       "cYwJA2A6I12KNkm2rtXd5g    147\n",
       "KskYqH1Bi7Z_61pH6Om8pg    116\n",
       "rcaPajgKOJC2vo_l3xa42A    108\n",
       "SMPbvZLSMMb7KU76YNYMGg    107\n",
       "                         ... \n",
       "Fi-2ruy5x600SX4avnrFuA     47\n",
       "r_BrIgzYcwo1NAuG9dLbpg     45\n",
       "9a3DrZvpYxVs3k_qwlCNSw     43\n",
       "kRgAf6j2y1eR0wOFdzFAuw     43\n",
       "Xg5qEQiB-7L6kGJ5F4K3bQ     43\n",
       "Name: business_id, Length: 42, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop samples of \"OTHERS\" to make the dataset more balanced\n",
    "drop_frac = (1 - 2*float(relabeled_text_and_rating_and_business_dist[1]) / relabeled_text_and_rating_and_business_dist[0])\n",
    "resampled_text_and_rating_and_business = relabeled_text_and_rating_and_business.drop(relabeled_text_and_rating_and_business[relabeled_text_and_rating_and_business['business_id'] == 'OTHERS'].sample(frac=drop_frac).index)\n",
    "print(\"Length of dataset after drops\", len(resampled_text_and_rating_and_business))\n",
    "resampled_text_and_rating_and_business.business_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, from the 100 businesses selected for the Text+Rating+Business dataset, only 41 are from the top 100 most frequent in the Text+Business dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the inputs and output to train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the texts and labels from the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_1 = text_and_ratings[\"text\"].values\n",
    "ratings_1 = text_and_ratings[\"stars\"].values\n",
    "\n",
    "texts_2 = resampled_text_and_business[\"text\"].values\n",
    "business_2 = resampled_text_and_business[\"business_id\"].values\n",
    "\n",
    "texts_3 = resampled_text_and_rating_and_business[\"text\"].values\n",
    "ratings_3 = resampled_text_and_rating_and_business[\"stars\"].values\n",
    "business_3 = resampled_text_and_rating_and_business[\"business_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = np.concatenate((texts_1, np.concatenate((texts_2, texts_3), axis=0)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a unique dictionary from the datasets. We will use this to create an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210792 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NUM_WORDS=5000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the strings (inputs) to sequences, and pad them. This is needed to train in mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_1 = tokenizer.texts_to_sequences(texts_1)\n",
    "sequences_2 = tokenizer.texts_to_sequences(texts_2)\n",
    "sequences_3 = tokenizer.texts_to_sequences(texts_3)\n",
    "sequences = sequences_1.copy()\n",
    "sequences.extend(sequences_2)\n",
    "sequences.extend(sequences_3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we build our dictionary and embedding layer, we should see how may words a texts usually has. So let's plot an hisotogram with that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sequences_word_length = [len (sample) for sample in sequences]\n",
    "texts_ch_length = [len (sample) for sample in texts]\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "f.suptitle('Reviews Length Distribution')\n",
    "f.set_size_inches((20, 5))\n",
    "ax1.hist(sequences_word_length, bins=100)\n",
    "ax1.set_title('In words')\n",
    "ax2.hist(texts_ch_length, bins=100)\n",
    "ax2.set_title('In characters')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a larger sequence, would mean that we would be truncating less samples, but it would also make the training process slower. So we will be a using a value that could be relatively not bad for both things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH=200 # max number of words in a review to use\n",
    "\n",
    "data_1 = pad_sequences(sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_2 = pad_sequences(sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_3 = pad_sequences(sequences_3, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the word_to_vec_map from Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    \"\"\"\n",
    "    Loads GloVe Model\n",
    "    \n",
    "    Arguments:\n",
    "    gloveFile -- path to the glove file\n",
    "\n",
    "    Returns:\n",
    "    embeddings_index -- a word_to_vec_map, where keys are words, and values are vectors (represented by arrays)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r')\n",
    "    embeddings_index = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        embeddings_index[word] = embedding\n",
    "    print(\"Done.\",len(embeddings_index),\" words loaded!\")\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "word_to_vec_map = loadGloveModel('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the embedding_matrix from the word_to_vec_map and our dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = word_to_vec_map[\"hello\"].shape[0] # how big is each word vector\n",
    "vocab_len = len(word_index) + 1\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_len, emb_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = word_to_vec_map.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(input_dim=vocab_len,\n",
    "                            output_dim=emb_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "inp = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "x = embedded_sequences = embedding_layer(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the ratings and businesses (outputs) to categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_1 = to_categorical(ratings_1, dtype='int8')\n",
    "labels_1.shape\n",
    "# 0 is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48850, 101)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_and_business_hashtable = {y:x for x, y in enumerate(resampled_text_and_business.business_id.unique())}\n",
    "labels_2 = np.array([text_and_business_hashtable.get(elem) for elem in business_2])\n",
    "labels_2 = to_categorical(labels_2, num_classes=101, dtype='int8')\n",
    "labels_2.shape\n",
    "# 100 + OTHERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3131, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_3a = to_categorical(ratings_3, num_classes=None, dtype='int8')\n",
    "labels_3a.shape\n",
    "# 0 is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3131, 101)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_3b = [text_and_business_hashtable.get(elem) for elem in business_3]\n",
    "labels_3b = to_categorical(labels_3b, num_classes=101, dtype='int8')\n",
    "labels_3b.shape\n",
    "# 100 + OTHERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight labels from dataset_1 and dataset_2 according to their frequency in the samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxi/.virtualenvs/py3/lib/python3.5/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.0, 1: 1.3878095, 2: 2.4515212, 3: 1.7856187, 4: 0.89981467, 5: 0.4545124}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weight_per_class = len(labels_1) / 5\n",
    "sum_labels_1 = labels_1.sum(axis=0).astype(np.float32)\n",
    "labels_1_weights = total_weight_per_class/sum_labels_1\n",
    "labels_1_weights[0] = 0\n",
    "labels_1_weights = dict( zip(range(0,labels_1.shape[1]+1),labels_1_weights ))\n",
    "labels_1_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=collections.Counter(np.argmax(labels_2, axis=1))\n",
    "labels_2_counts = dict(counter).values()\n",
    "total_weight_per_class = len(labels_2) / 101\n",
    "labels_2_weights = [total_weight_per_class/ float(x) for x in labels_2_counts]\n",
    "labels_2_weights = dict( zip(range(0,len(text_and_business_hashtable)+1),labels_2_weights ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model class. The hyperparams will be tuned separately for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(object):\n",
    "    \n",
    "    def __init__(self, hyperparams):\n",
    "        \n",
    "        # hyperparams is dict that contains the hyperparams of one model\n",
    "        \n",
    "        embedding_layer = Embedding(input_dim=vocab_len,\n",
    "                                    output_dim=emb_dim,\n",
    "                                    weights=[embedding_matrix],\n",
    "                                    input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                    trainable=False)\n",
    "        inp = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "        x = embedded_sequences = embedding_layer(inp)\n",
    "        x = Bidirectional(LSTM(emb_dim, return_sequences=True, dropout=hyperparams[\"LSTM_DROPOUT\"], recurrent_dropout=hyperparams[\"LSTM_RECURRENT_DROPOUT\"]))(x)\n",
    "        x = GlobalMaxPool1D()(x)\n",
    "        x = Dense(hyperparams[\"1_FC_SIZE\"], activation=\"relu\")(x)\n",
    "        x = BatchNormalization(axis=1)(x)\n",
    "        x = Dropout(hyperparams[\"1_FC_DROPOUT\"])(x)\n",
    "        x = Dense(hyperparams[\"2_FC_SIZE\"], activation=\"relu\")(x)\n",
    "        x = BatchNormalization(axis=1)(x)\n",
    "        x = Dropout(hyperparams[\"2_FC_DROPOUT\"])(x)\n",
    "        y = Dense(hyperparams[\"FINAL_SIZE\"], activation=\"softmax\")(x)\n",
    "        self.model = Model(inputs=inp, outputs=y)\n",
    "        return\n",
    "\n",
    "    def train(self, train_params, train_data, train_labels, eval_data, eval_labels, labels_weights, checkpoints=False):        \n",
    "        \n",
    "        self.train_params = train_params\n",
    "        \n",
    "        if checkpoints:\n",
    "            # using checkpoints\n",
    "            # include the epoch in the file name. (uses `str.format`)\n",
    "            checkpoint_path = \"./cp-{epoch:04d}.ckpt\"\n",
    "            checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "            # Create checkpoint callback\n",
    "            cp_callback = callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                    save_weights_only=True, # as I know the model architecture, I can save the weights only\n",
    "                                                    period=1, # every 1 epoch (default)\n",
    "                                                    verbose=1)\n",
    "            model_callbacks = [cp_callback]\n",
    "            self.model.save_weights(checkpoint_path.format(epoch=0))\n",
    "        else:\n",
    "            model_callbacks = None\n",
    "\n",
    "        print (\"Training model...\")\n",
    "        start = time.clock()\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='Adamax', weighted_metrics=['categorical_accuracy'])\n",
    "        self.history = self.model.fit(train_data, train_labels,\n",
    "                            batch_size=train_params[\"BATCH_SIZE\"], epochs=train_params[\"NUM_EPOCHS\"],\n",
    "                            shuffle=True, verbose=1,\n",
    "                            validation_data = (eval_data, eval_labels),\n",
    "                            class_weight = labels_weights,\n",
    "                            callbacks=model_callbacks)\n",
    "        end = time.clock()\n",
    "        self.train_time = end-start\n",
    "        print('Time spent: [s]: {:0.0f}'.format(self.train_time))\n",
    "\n",
    "        print (\"Evaluating model...\")\n",
    "        _, self.train_acc = self.model.evaluate(train_data, train_labels, batch_size=train_params[\"BATCH_SIZE\"], verbose=1)\n",
    "        self.eval_loss, self.eval_acc = self.model.evaluate(eval_data, eval_labels, batch_size=train_params[\"BATCH_SIZE\"], verbose=1)\n",
    "\n",
    "        return (self.train_acc, self.eval_loss, self.eval_acc, self.train_time)\n",
    "    \n",
    "    def print_statistics(self):\n",
    "        print('Train accuracy [%]: ', (self.train_acc*100))\n",
    "        print('Eval accuracy [%]: ', (self.eval_acc*100))\n",
    "        print('Bias [%]: ', ((1-self.train_acc)*100))\n",
    "        print('Variance [%]: ', (((1-self.eval_acc) - (1-self.train_acc))*100))\n",
    "        return\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.style.use(\"ggplot\")\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(0, self.train_params[\"NUM_EPOCHS\"]), self.model.history.history[\"loss\"], label=\"train_loss\")\n",
    "        plt.plot(np.arange(0, self.train_params[\"NUM_EPOCHS\"]), self.model.history.history[\"val_loss\"], label=\"val_loss\")\n",
    "        plt.title(\"Training Loss Curves\")\n",
    "        plt.xlabel(\"Epoch #\")\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.savefig(\"loss_plot.png\")\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_error(self):\n",
    "        plt.style.use(\"ggplot\")\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(0, self.train_params[\"NUM_EPOCHS\"]), 100*(1-np.array(self.model.history.history[\"weighted_categorical_accuracy\"])), label=\"train_error\")\n",
    "        plt.plot(np.arange(0, self.train_params[\"NUM_EPOCHS\"]), 100*(1-np.array(self.model.history.history[\"val_weighted_categorical_accuracy\"])), label=\"val_error\")\n",
    "        plt.title(\"Training Error Curves\")\n",
    "        plt.xlabel(\"Epoch #\")\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.savefig(\"loss_plot.png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper class for hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTuningStep(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    # Helper function to clean memory\n",
    "    def reset_keras(self):\n",
    "        sess = get_session()\n",
    "        clear_session()\n",
    "        sess.close()\n",
    "        sess = get_session()\n",
    "\n",
    "        try:\n",
    "            del classifier # this is from global space - change this as you need\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        # use the same config as you used to create the session\n",
    "        config = tensorflow.ConfigProto()\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "        config.gpu_options.visible_device_list = \"0\"\n",
    "        set_session(tensorflow.Session(config=config))    \n",
    "    \n",
    "    def train_tuning_step_with_holdout(self, train_params, list_of_hyperparams, data, labels, labels_weights, val_split, random_state=None, checkpoints=False):\n",
    "\n",
    "        num_models = len(list_of_hyperparams)\n",
    "\n",
    "        self.train_accs = np.zeros((num_models))\n",
    "        self.eval_losses = np.zeros((num_models))\n",
    "        self.eval_accs = np.zeros((num_models))\n",
    "        self.train_times = np.zeros((num_models))\n",
    "\n",
    "        # Split data/labels in train and eval\n",
    "        train_data, eval_data, train_labels, eval_labels = train_test_split(data, labels, test_size=val_split, random_state=random_state, stratify=np.argmax(labels, axis=1))\n",
    "\n",
    "        for i_model in range (num_models):\n",
    "\n",
    "            print (\"MODEL: \", i_model)\n",
    "\n",
    "            self.reset_keras()\n",
    "            model = MyModel(list_of_hyperparams[i_model])\n",
    "            model.model.compile(loss='categorical_crossentropy', optimizer='Adamax', weighted_metrics=['categorical_accuracy'])\n",
    "            model.model.summary()\n",
    "            self.train_accs[i_model], self.eval_losses[i_model], self.eval_accs[i_model], self.train_times[i_model] = model.train(train_params, train_data, train_labels, eval_data, eval_labels, labels_weights, checkpoints=checkpoints)\n",
    "\n",
    "        return (self.train_accs, self.eval_losses, self.eval_accs, self.train_times)\n",
    "    \n",
    "    def train_tuning_step_with_kfolds(self, train_params, list_of_hyperparams, data, labels, labels_weights, k_folds, checkpoints=False):\n",
    "\n",
    "        num_models = len(list_of_hyperparams)\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=k_folds)\n",
    "\n",
    "        self.train_accs = np.zeros((num_models,k_folds))\n",
    "        self.eval_losses = np.zeros((num_models,k_folds))\n",
    "        self.eval_accs = np.zeros((num_models,k_folds))\n",
    "        self.train_times = np.zeros((num_models,k_folds))\n",
    "\n",
    "        for i_model in range (num_models):\n",
    "            print (\"MODEL: \", i_model)\n",
    "            i_fold=0\n",
    "            for train_index, eval_index in skf.split(data, np.argmax(labels, axis=1)):\n",
    "                print (\"FOLD: \", i_fold)\n",
    "\n",
    "                train_data, eval_data = data[train_index], data[eval_index]\n",
    "                train_labels, eval_labels = labels[train_index], labels[eval_index]\n",
    "\n",
    "                self.reset_keras()\n",
    "                model = MyModel(list_of_hyperparams[i_model])\n",
    "                model.model.compile(loss='categorical_crossentropy', optimizer='Adamax', weighted_metrics=['categorical_accuracy'])\n",
    "                self.train_accs[i_model,i_fold], self.eval_losses[i_model,i_fold], self.eval_accs[i_model,i_fold], self.train_times[i_model,i_fold] = model.train(train_params, train_data, train_labels, eval_data, eval_labels, labels_weights, checkpoints=checkpoints)\n",
    "\n",
    "                i_fold += 1\n",
    "                \n",
    "        self.train_accs = self.train_accs.mean(axis=1)\n",
    "        self.eval_losses = self.eval_losses.mean(axis=1)\n",
    "        self.eval_accs = self.eval_accs.mean(axis=1)\n",
    "        self.train_times = self.train_times.mean(axis=1)       \n",
    "\n",
    "        return (self.train_accs, self.eval_losses, self.eval_accs, self.train_times)\n",
    "    \n",
    "    def print_statistics(self):\n",
    "        print('Train accuracy [%]: ', (self.train_accs*100))\n",
    "        print('Eval accuracy [%]: ', (self.eval_accs*100))\n",
    "        print('Bias [%]: ', ((1-self.train_accs)*100))\n",
    "        print('Variance [%]: ', (((1-self.eval_accs) - (1-self.train_accs))*100))\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 (ratings output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be tuning hyperparameters (4 configurations per step) with holdout cross-validation (the test/train split is small, so maybe we don't need to use k-folds) and a small number of epochs (I'm just trying to find which hyperparameters could work better, not to train a final model, so the first epochs give me an idea in a short amount of time). At first, we will not using drop-put (we will add it later if we need to reduce overfitting). We will look at the weighted bias and variance and tune the hyperparameters in next steps to get better results, until we no longer progress that much. Then, using those hyperparameters, we will train one more model with more epochs, and using checkpoints. At the end, we will just keep the checkpoint with the best performance (just before it starts to overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    \"BATCH_SIZE\": 512, # I tuned this number by increasing it until the first showed ETA didn't changed,\n",
    "                        # or I had some problem with the memory\n",
    "    \"NUM_EPOCHS\": 2\n",
    "}\n",
    "val_split = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1st set of hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_hyperparams = [\n",
    "                    {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 64,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 16,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_1.shape[1]\n",
    "                    },\n",
    "                    {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 64,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 32,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_1.shape[1]\n",
    "                    },\n",
    "                    {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 128,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 32,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_1.shape[1]\n",
    "                    },\n",
    "                    {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 256,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 64,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_1.shape[1]\n",
    "                    }\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL:  0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 50)           10539650  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200, 100)          40400     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 10,587,976\n",
      "Trainable params: 48,166\n",
      "Non-trainable params: 10,539,810\n",
      "_________________________________________________________________\n",
      "Training model...\n",
      "Train on 475000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "475000/475000 [==============================] - 629s 1ms/step - loss: 1.1637 - weighted_categorical_accuracy: 0.5033 - val_loss: 1.0742 - val_weighted_categorical_accuracy: 0.5652\n",
      "Epoch 2/2\n",
      "475000/475000 [==============================] - 549s 1ms/step - loss: 0.9800 - weighted_categorical_accuracy: 0.5741 - val_loss: 0.8834 - val_weighted_categorical_accuracy: 0.6284\n",
      "Time spent: [s]: 1577\n",
      "Evaluating model...\n",
      "475000/475000 [==============================] - 190s 400us/step\n",
      "25000/25000 [==============================] - 10s 400us/step\n",
      "MODEL:  1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 50)           10539650  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200, 100)          40400     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 10,589,176\n",
      "Trainable params: 49,334\n",
      "Non-trainable params: 10,539,842\n",
      "_________________________________________________________________\n",
      "Training model...\n",
      "Train on 475000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "475000/475000 [==============================] - 599s 1ms/step - loss: 1.1703 - weighted_categorical_accuracy: 0.5023 - val_loss: 0.9311 - val_weighted_categorical_accuracy: 0.5938\n",
      "Epoch 2/2\n",
      "475000/475000 [==============================] - 579s 1ms/step - loss: 0.9875 - weighted_categorical_accuracy: 0.5694 - val_loss: 0.8824 - val_weighted_categorical_accuracy: 0.6149\n",
      "Time spent: [s]: 1618\n",
      "Evaluating model...\n",
      "475000/475000 [==============================] - 196s 413us/step\n",
      "25000/25000 [==============================] - 10s 414us/step\n",
      "MODEL:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 50)           10539650  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200, 100)          40400     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 10,597,944\n",
      "Trainable params: 57,974\n",
      "Non-trainable params: 10,539,970\n",
      "_________________________________________________________________\n",
      "Training model...\n",
      "Train on 475000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "475000/475000 [==============================] - 538s 1ms/step - loss: 1.1386 - weighted_categorical_accuracy: 0.5131 - val_loss: 0.9120 - val_weighted_categorical_accuracy: 0.6266\n",
      "Epoch 2/2\n",
      "475000/475000 [==============================] - 537s 1ms/step - loss: 0.9760 - weighted_categorical_accuracy: 0.5750 - val_loss: 1.0608 - val_weighted_categorical_accuracy: 0.5638\n",
      "Time spent: [s]: 1767\n",
      "Evaluating model...\n",
      "475000/475000 [==============================] - 194s 409us/step\n",
      "25000/25000 [==============================] - 10s 402us/step\n",
      "MODEL:  3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 50)           10539650  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200, 100)          40400     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 10,624,024\n",
      "Trainable params: 83,734\n",
      "Non-trainable params: 10,540,290\n",
      "_________________________________________________________________\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 475000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "475000/475000 [==============================] - 526s 1ms/step - loss: 1.1221 - weighted_categorical_accuracy: 0.5184 - val_loss: 0.9133 - val_weighted_categorical_accuracy: 0.6129\n",
      "Epoch 2/2\n",
      "475000/475000 [==============================] - 527s 1ms/step - loss: 0.9760 - weighted_categorical_accuracy: 0.5744 - val_loss: 1.1154 - val_weighted_categorical_accuracy: 0.5626\n",
      "Time spent: [s]: 1709\n",
      "Evaluating model...\n",
      "475000/475000 [==============================] - 196s 414us/step\n",
      "25000/25000 [==============================] - 10s 397us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.63223368, 0.62223368, 0.56370737, 0.56480842]),\n",
       " array([0.88343825, 0.88239325, 1.06080981, 1.11538899]),\n",
       " array([0.62844, 0.61492, 0.5638 , 0.5626 ]),\n",
       " array([1576.922191, 1617.699696, 1767.408013, 1708.770826]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_step = MyTuningStep()\n",
    "tuning_step.train_tuning_step_with_holdout(train_params=train_params, list_of_hyperparams=list_of_hyperparams, data=data_1, labels=labels_1, labels_weights=labels_1_weights, val_split=val_split, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy [%]:  [63.22336842 62.22336842 56.37073684 56.4808421 ]\n",
      "Eval accuracy [%]:  [62.84399998 61.49199999 56.37999997 56.26000002]\n",
      "Bias [%]:  [36.77663158 37.77663158 43.62926316 43.5191579 ]\n",
      "Variance [%]:  [ 0.37936844  0.73136843 -0.00926313  0.22084209]\n"
     ]
    }
   ],
   "source": [
    "tuning_step.print_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2st set of hyperparams\n",
    "So the best configuration was the set 0, which is the one with less trainable params. So that probably means that need to train less complex models instead of more complex ones. Let's try some more sets similar to that one, to see what happens, and just in case, one more complex one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_hyperparams = [\n",
    "                    {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 32,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 16,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_1.shape[1]\n",
    "                    },\n",
    "                    {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 64,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 8,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_1.shape[1]\n",
    "                    },\n",
    "                    {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 32,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 8,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_1.shape[1]\n",
    "                    },\n",
    "                    {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 128,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 64,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_1.shape[1]\n",
    "                    }    \n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL:  0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 50)           10539650  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200, 100)          40400     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 10,584,104\n",
      "Trainable params: 44,358\n",
      "Non-trainable params: 10,539,746\n",
      "_________________________________________________________________\n",
      "Training model...\n",
      "Train on 475000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "475000/475000 [==============================] - 581s 1ms/step - loss: 1.1850 - weighted_categorical_accuracy: 0.4992 - val_loss: 0.9098 - val_weighted_categorical_accuracy: 0.6157\n",
      "Epoch 2/2\n",
      "475000/475000 [==============================] - 645s 1ms/step - loss: 0.9856 - weighted_categorical_accuracy: 0.5714 - val_loss: 0.8857 - val_weighted_categorical_accuracy: 0.6216\n",
      "Time spent: [s]: 1621\n",
      "Evaluating model...\n",
      "475000/475000 [==============================] - 242s 508us/step\n",
      "25000/25000 [==============================] - 12s 465us/step\n",
      "MODEL:  1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 50)           10539650  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200, 100)          40400     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 10,587,376\n",
      "Trainable params: 47,582\n",
      "Non-trainable params: 10,539,794\n",
      "_________________________________________________________________\n",
      "Training model...\n",
      "Train on 475000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "475000/475000 [==============================] - 598s 1ms/step - loss: 1.1515 - weighted_categorical_accuracy: 0.5140 - val_loss: 0.9302 - val_weighted_categorical_accuracy: 0.6128\n",
      "Epoch 2/2\n",
      "475000/475000 [==============================] - 526s 1ms/step - loss: 0.9722 - weighted_categorical_accuracy: 0.5779 - val_loss: 0.8375 - val_weighted_categorical_accuracy: 0.6433\n",
      "Time spent: [s]: 1581\n",
      "Evaluating model...\n",
      "475000/475000 [==============================] - 190s 399us/step\n",
      "25000/25000 [==============================] - 10s 400us/step\n",
      "MODEL:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 50)           10539650  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200, 100)          40400     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 10,583,760\n",
      "Trainable params: 44,030\n",
      "Non-trainable params: 10,539,730\n",
      "_________________________________________________________________\n",
      "Training model...\n",
      "Train on 475000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "475000/475000 [==============================] - 518s 1ms/step - loss: 1.1773 - weighted_categorical_accuracy: 0.5033 - val_loss: 0.9650 - val_weighted_categorical_accuracy: 0.5850\n",
      "Epoch 2/2\n",
      "475000/475000 [==============================] - 547s 1ms/step - loss: 0.9820 - weighted_categorical_accuracy: 0.5731 - val_loss: 0.8889 - val_weighted_categorical_accuracy: 0.6189\n",
      "Time spent: [s]: 1494\n",
      "Evaluating model...\n",
      "475000/475000 [==============================] - 232s 489us/step\n",
      "25000/25000 [==============================] - 10s 404us/step\n",
      "MODEL:  3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 50)           10539650  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200, 100)          40400     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 10,602,392\n",
      "Trainable params: 62,358\n",
      "Non-trainable params: 10,540,034\n",
      "_________________________________________________________________\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 475000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "475000/475000 [==============================] - 593s 1ms/step - loss: 1.1248 - weighted_categorical_accuracy: 0.5190 - val_loss: 1.2727 - val_weighted_categorical_accuracy: 0.5031\n",
      "Epoch 2/2\n",
      "475000/475000 [==============================] - 609s 1ms/step - loss: 0.9740 - weighted_categorical_accuracy: 0.5754 - val_loss: 0.9385 - val_weighted_categorical_accuracy: 0.6147\n",
      "Time spent: [s]: 1634\n",
      "Evaluating model...\n",
      "475000/475000 [==============================] - 236s 496us/step\n",
      "25000/25000 [==============================] - 11s 437us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.62946947, 0.64769474, 0.62852211, 0.61872   ]),\n",
       " array([0.88572204, 0.83752394, 0.88885351, 0.93851581]),\n",
       " array([0.62164, 0.64332, 0.61888, 0.61468]),\n",
       " array([1621.347295, 1581.152128, 1494.071803, 1633.723122]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As We are using holdout, we will change the random_state in order to avoid overfitting the test-set with the hyperparameters tuning\n",
    "tuning_step.train_tuning_step_with_holdout(train_params=train_params, list_of_hyperparams=list_of_hyperparams, data=data_1, labels=labels_1, labels_weights=labels_1_weights, val_split=val_split, random_state=321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy [%]:  [62.94694737 64.76947368 62.85221053 61.872     ]\n",
      "Eval accuracy [%]:  [62.16400005 64.33199998 61.88800001 61.46799998]\n",
      "Bias [%]:  [37.05305263 35.23052632 37.14778947 38.128     ]\n",
      "Variance [%]:  [0.78294732 0.43747371 0.96421052 0.40400002]\n"
     ]
    }
   ],
   "source": [
    "tuning_step.print_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final set of hyperparams\n",
    "We could keep testing sets of hyperparameters if more time was given, but just to go on with the challenge, let's choose the set of hyperparameters with lowest bias and train a model with much more epochs, and see what happens. Now we will use checkpoints in case we need to use a model state different than the final one. We still have too much bias, so we will try to reduce it before adding dropout to improve variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "            \"LSTM_DROPOUT\" : 0,\n",
    "            \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "            \"1_FC_SIZE\" : 64,\n",
    "            \"1_FC_DROPOUT\" : 0,\n",
    "            \"2_FC_SIZE\" : 8,\n",
    "            \"2_FC_DROPOUT\" : 0,\n",
    "            \"FINAL_SIZE\" : labels_1.shape[1]\n",
    "            }\n",
    "\n",
    "train_params = {\n",
    "    \"BATCH_SIZE\": 1024, # I tuned this number by increasing it until the first showed ETA didn't changed\n",
    "    \"NUM_EPOCHS\": 10\n",
    "}\n",
    "val_split = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 475000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "475000/475000 [==============================] - 754s 2ms/step - loss: 1.2254 - weighted_categorical_accuracy: 0.4988 - val_loss: 1.0858 - val_weighted_categorical_accuracy: 0.5487\n",
      "\n",
      "Epoch 00001: saving model to ./cp-0001.ckpt\n",
      "Epoch 2/10\n",
      "475000/475000 [==============================] - 726s 2ms/step - loss: 1.0150 - weighted_categorical_accuracy: 0.5649 - val_loss: 0.9854 - val_weighted_categorical_accuracy: 0.5916\n",
      "\n",
      "Epoch 00002: saving model to ./cp-0002.ckpt\n",
      "Epoch 3/10\n",
      "475000/475000 [==============================] - 727s 2ms/step - loss: 0.9612 - weighted_categorical_accuracy: 0.5841 - val_loss: 0.8607 - val_weighted_categorical_accuracy: 0.6395\n",
      "\n",
      "Epoch 00003: saving model to ./cp-0003.ckpt\n",
      "Epoch 4/10\n",
      "475000/475000 [==============================] - 727s 2ms/step - loss: 0.9330 - weighted_categorical_accuracy: 0.5948 - val_loss: 0.8281 - val_weighted_categorical_accuracy: 0.6498\n",
      "\n",
      "Epoch 00004: saving model to ./cp-0004.ckpt\n",
      "Epoch 5/10\n",
      "475000/475000 [==============================] - 727s 2ms/step - loss: 0.9154 - weighted_categorical_accuracy: 0.6024 - val_loss: 0.8209 - val_weighted_categorical_accuracy: 0.6510\n",
      "\n",
      "Epoch 00005: saving model to ./cp-0005.ckpt\n",
      "Epoch 6/10\n",
      "475000/475000 [==============================] - 733s 2ms/step - loss: 0.9011 - weighted_categorical_accuracy: 0.6075 - val_loss: 0.9692 - val_weighted_categorical_accuracy: 0.5931\n",
      "\n",
      "Epoch 00006: saving model to ./cp-0006.ckpt\n",
      "Epoch 7/10\n",
      "475000/475000 [==============================] - 834s 2ms/step - loss: 0.8899 - weighted_categorical_accuracy: 0.6125 - val_loss: 0.8151 - val_weighted_categorical_accuracy: 0.6501\n",
      "\n",
      "Epoch 00007: saving model to ./cp-0007.ckpt\n",
      "Epoch 8/10\n",
      "475000/475000 [==============================] - 797s 2ms/step - loss: 0.8807 - weighted_categorical_accuracy: 0.6167 - val_loss: 0.8701 - val_weighted_categorical_accuracy: 0.6247\n",
      "\n",
      "Epoch 00008: saving model to ./cp-0008.ckpt\n",
      "Epoch 9/10\n",
      "475000/475000 [==============================] - 792s 2ms/step - loss: 0.8729 - weighted_categorical_accuracy: 0.6196 - val_loss: 1.0574 - val_weighted_categorical_accuracy: 0.5352\n",
      "\n",
      "Epoch 00009: saving model to ./cp-0009.ckpt\n",
      "Epoch 10/10\n",
      "475000/475000 [==============================] - 742s 2ms/step - loss: 0.8663 - weighted_categorical_accuracy: 0.6228 - val_loss: 0.7795 - val_weighted_categorical_accuracy: 0.6671\n",
      "\n",
      "Epoch 00010: saving model to ./cp-0010.ckpt\n",
      "Time spent: [s]: 8372\n",
      "Evaluating model...\n",
      "475000/475000 [==============================] - 164s 346us/step\n",
      "25000/25000 [==============================] - 10s 389us/step\n",
      "Train accuracy [%]:  67.97768421022515\n",
      "Eval accuracy [%]:  66.70800001144408\n",
      "Bias [%]:  32.022315789774844\n",
      "Variance [%]:  1.2696841987810625\n"
     ]
    }
   ],
   "source": [
    "train_data_1, eval_data_1, train_labels_1, eval_labels_1 = train_test_split(data_1, labels_1, test_size=val_split, random_state=456, stratify=np.argmax(labels_1, axis=1))\n",
    "\n",
    "tuning_step.reset_keras()\n",
    "\n",
    "my_model_1 = MyModel(hyperparams)\n",
    "my_model_1.train(train_params, train_data_1, train_labels_1, eval_data_1, eval_labels_1, labels_1_weights, checkpoints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy [%]:  67.97768421022515\n",
      "Eval accuracy [%]:  66.70800001144408\n",
      "Bias [%]:  32.022315789774844\n",
      "Variance [%]:  1.2696841987810625\n"
     ]
    }
   ],
   "source": [
    "my_model_1.print_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some plots to see the progess of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_model_1.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we could train more epochs, as the loss is still reducing and the val_loss doesn't seem to be increasing. and therefore the model is not overfitting yet. So let's train some more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 475000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "475000/475000 [==============================] - 813s 2ms/step - loss: 0.8616 - weighted_categorical_accuracy: 0.6252 - val_loss: 0.9010 - val_weighted_categorical_accuracy: 0.6018\n",
      "\n",
      "Epoch 00001: saving model to ./cp-0001.ckpt\n",
      "Epoch 2/10\n",
      "475000/475000 [==============================] - 847s 2ms/step - loss: 0.8546 - weighted_categorical_accuracy: 0.6282 - val_loss: 0.8245 - val_weighted_categorical_accuracy: 0.6376\n",
      "\n",
      "Epoch 00002: saving model to ./cp-0002.ckpt\n",
      "Epoch 3/10\n",
      "475000/475000 [==============================] - 830s 2ms/step - loss: 0.8494 - weighted_categorical_accuracy: 0.6305 - val_loss: 0.8555 - val_weighted_categorical_accuracy: 0.6290\n",
      "\n",
      "Epoch 00003: saving model to ./cp-0003.ckpt\n",
      "Epoch 4/10\n",
      "475000/475000 [==============================] - 806s 2ms/step - loss: 0.8451 - weighted_categorical_accuracy: 0.6325 - val_loss: 0.7715 - val_weighted_categorical_accuracy: 0.6693\n",
      "\n",
      "Epoch 00004: saving model to ./cp-0004.ckpt\n",
      "Epoch 5/10\n",
      "475000/475000 [==============================] - 781s 2ms/step - loss: 0.8411 - weighted_categorical_accuracy: 0.6350 - val_loss: 0.7979 - val_weighted_categorical_accuracy: 0.6566\n",
      "\n",
      "Epoch 00005: saving model to ./cp-0005.ckpt\n",
      "Epoch 6/10\n",
      "475000/475000 [==============================] - 806s 2ms/step - loss: 0.8378 - weighted_categorical_accuracy: 0.6362 - val_loss: 0.8228 - val_weighted_categorical_accuracy: 0.6462\n",
      "\n",
      "Epoch 00006: saving model to ./cp-0006.ckpt\n",
      "Epoch 7/10\n",
      "475000/475000 [==============================] - 805s 2ms/step - loss: 0.8336 - weighted_categorical_accuracy: 0.6378 - val_loss: 0.7783 - val_weighted_categorical_accuracy: 0.6641\n",
      "\n",
      "Epoch 00007: saving model to ./cp-0007.ckpt\n",
      "Epoch 8/10\n",
      "475000/475000 [==============================] - 773s 2ms/step - loss: 0.8303 - weighted_categorical_accuracy: 0.6396 - val_loss: 0.8131 - val_weighted_categorical_accuracy: 0.6490\n",
      "\n",
      "Epoch 00008: saving model to ./cp-0008.ckpt\n",
      "Epoch 9/10\n",
      "475000/475000 [==============================] - 806s 2ms/step - loss: 0.8267 - weighted_categorical_accuracy: 0.6407 - val_loss: 1.0066 - val_weighted_categorical_accuracy: 0.5717\n",
      "\n",
      "Epoch 00009: saving model to ./cp-0009.ckpt\n",
      "Epoch 10/10\n",
      "475000/475000 [==============================] - 809s 2ms/step - loss: 0.8239 - weighted_categorical_accuracy: 0.6419 - val_loss: 0.8452 - val_weighted_categorical_accuracy: 0.6330\n",
      "\n",
      "Epoch 00010: saving model to ./cp-0010.ckpt\n",
      "Time spent: [s]: 8570\n",
      "Evaluating model...\n",
      "475000/475000 [==============================] - 164s 345us/step\n",
      "25000/25000 [==============================] - 9s 349us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6543263157543383, 0.8451820698738098, 0.6330000003242493, 8569.840616999998)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_1.train(train_params, train_data_1, train_labels_1, eval_data_1, eval_labels_1, labels_1_weights, checkpoints=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy [%]:  65.43263157543383\n",
      "Eval accuracy [%]:  63.30000003242493\n",
      "Bias [%]:  34.56736842456617\n",
      "Variance [%]:  2.1326315430089005\n"
     ]
    }
   ],
   "source": [
    "my_model_1.print_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_model_1.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the val_loss is probably starting to increase, so the model is starting to overfit maybe (we have some noise that makes it difficult to know exactly though). We could try to improve this trining more epochs but using dropout. But for now we will keep the checkpoint with the best performance and continue with the rest of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./cp-0004.ckpt\"\n",
    "my_model_1.model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will make predictions on dataset_3 (Text+Rating+Business.csv) to get some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3131/3131 [==============================] - 2s 573us/step\n"
     ]
    }
   ],
   "source": [
    "predictions_ratings_data_3 = my_model_1.model.predict(data_3, batch_size=train_params[\"BATCH_SIZE\"], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the real name of the business (instead of the id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_3_names = sorted(text_and_business_hashtable, key=text_and_business_hashtable.get)\n",
    "\n",
    "business_infos = []\n",
    "for line in open('yelp_academic_dataset_business.json', 'r'):\n",
    "    business_infos.append(json.loads(line))\n",
    "real_labels_3_names = labels_3_names\n",
    "\n",
    "for business_info in business_infos:\n",
    "    for idx,labels_3_name in enumerate(labels_3_names):\n",
    "        if business_info[\"business_id\"]==labels_3_name:\n",
    "            real_labels_3_names[idx]=business_info[\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And show the corresponding metrics for a multi-class classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxi/.virtualenvs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/maxi/.virtualenvs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.764063</td>\n",
       "      <td>0.668954</td>\n",
       "      <td>0.568995</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.460472</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.775678</td>\n",
       "      <td>0.752896</td>\n",
       "      <td>0.539871</td>\n",
       "      <td>0.405530</td>\n",
       "      <td>0.566553</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.752791</td>\n",
       "      <td>0.601852</td>\n",
       "      <td>0.601441</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.387850</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>1254.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>833.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     5           1           4           2           3    0\n",
       "f1-score      0.764063    0.668954    0.568995    0.484848    0.460472  0.0\n",
       "precision     0.775678    0.752896    0.539871    0.405530    0.566553  0.0\n",
       "recall        0.752791    0.601852    0.601441    0.602740    0.387850  0.0\n",
       "support    1254.000000  324.000000  833.000000  292.000000  428.000000  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = classification_report(y_true=ratings_3, y_pred=predictions_ratings_data_3.argmax(axis=1), labels=range(0,labels_1.shape[1]), output_dict=True)\n",
    "df_report = pd.DataFrame(report)\n",
    "metrics_cols = ['micro avg', 'macro avg', 'weighted avg']\n",
    "df_report_by_review = df_report.drop(columns=metrics_cols, inplace=False).sort_values(by=\"f1-score\", axis=1, ascending=False)\n",
    "display(df_report_by_review)\n",
    "df_report.to_csv(\"report_model_1_by_review.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model classifies better the 5-star reviews than the 3-stars reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>macro avg</th>\n",
       "      <th>micro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.491222</td>\n",
       "      <td>0.633025</td>\n",
       "      <td>0.634783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.506755</td>\n",
       "      <td>0.633025</td>\n",
       "      <td>0.647477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.491112</td>\n",
       "      <td>0.633025</td>\n",
       "      <td>0.633025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>3131.000000</td>\n",
       "      <td>3131.000000</td>\n",
       "      <td>3131.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             macro avg    micro avg  weighted avg\n",
       "f1-score      0.491222     0.633025      0.634783\n",
       "precision     0.506755     0.633025      0.647477\n",
       "recall        0.491112     0.633025      0.633025\n",
       "support    3131.000000  3131.000000   3131.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_cols = df_report.columns.values.tolist()\n",
    "drop_cols = (set(all_cols)-set(metrics_cols))\n",
    "df_report_by_metrics = df_report.drop(columns=drop_cols, inplace=False)\n",
    "display(df_report_by_metrics)\n",
    "df_report.to_csv(\"report_model_1_by_metrics.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will make the inferences of the ratings/stars of the texts from MyExperiences.csv. We will be reading this file in chunks, as it is too large (and unnecessary) to open it completely. But we can increase the batch_size for the inference process, as it uses less memory than the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 33s 327us/step\n",
      "100000/100000 [==============================] - 31s 314us/step\n",
      " 28672/100000 [=======>......................] - ETA: 23s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-c1b58ed3e461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mchunk_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BATCH_SIZE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stars\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./MyExperiences_ratings.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.virtualenvs/py3/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chunksize = 10 ** 5\n",
    "for chunk in pd.read_csv(\"MyExperiences.csv\", usecols=[\"review_id\",\"text\"], chunksize=chunksize):\n",
    "    texts = chunk[\"text\"].values\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    chunk_predictions = my_model_1.model.predict(data, batch_size=4*train_params[\"BATCH_SIZE\"], verbose=1)\n",
    "    chunk[\"stars\"] = np.argmax(chunk_predictions, axis=1)\n",
    "    chunk.to_csv(\"./MyExperiences_ratings.csv\", mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I stopped the last cell just because it takes too much time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 (business output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model we will train with k-folds cross-validatoin, as the dataset is smaller, and therefore more prone to overfit to test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    \"BATCH_SIZE\": 512,\n",
    "    \"NUM_EPOCHS\": 5\n",
    "}\n",
    "k_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1st set of hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_hyperparams = [\n",
    "                    {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 64,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 16,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_2.shape[1]\n",
    "                    },\n",
    "                    {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 64,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 32,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_2.shape[1]\n",
    "                    },\n",
    "                    {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 128,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 32,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_2.shape[1]\n",
    "                    },\n",
    "                    {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 256,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 64,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_2.shape[1]\n",
    "                    }\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL:  0\n",
      "FOLD:  0\n",
      "Training model...\n",
      "Train on 39038 samples, validate on 9812 samples\n",
      "Epoch 1/5\n",
      "39038/39038 [==============================] - 52s 1ms/step - loss: 4.4662 - weighted_categorical_accuracy: 0.0273 - val_loss: 4.3261 - val_weighted_categorical_accuracy: 0.0388\n",
      "Epoch 2/5\n",
      "39038/39038 [==============================] - 48s 1ms/step - loss: 4.0648 - weighted_categorical_accuracy: 0.0815 - val_loss: 4.0100 - val_weighted_categorical_accuracy: 0.0754\n",
      "Epoch 3/5\n",
      "39038/39038 [==============================] - 48s 1ms/step - loss: 3.7226 - weighted_categorical_accuracy: 0.1483 - val_loss: 3.6259 - val_weighted_categorical_accuracy: 0.1478\n",
      "Epoch 4/5\n",
      "39038/39038 [==============================] - 48s 1ms/step - loss: 3.4094 - weighted_categorical_accuracy: 0.1958 - val_loss: 3.3947 - val_weighted_categorical_accuracy: 0.1779\n",
      "Epoch 5/5\n",
      "39038/39038 [==============================] - 48s 1ms/step - loss: 3.1457 - weighted_categorical_accuracy: 0.2392 - val_loss: 3.1840 - val_weighted_categorical_accuracy: 0.2220\n",
      "Time spent: [s]: 350\n",
      "Evaluating model...\n",
      "39038/39038 [==============================] - 18s 468us/step\n",
      "9812/9812 [==============================] - 5s 479us/step\n",
      "FOLD:  1\n",
      "Training model...\n",
      "Train on 39062 samples, validate on 9788 samples\n",
      "Epoch 1/5\n",
      "39062/39062 [==============================] - 56s 1ms/step - loss: 4.5171 - weighted_categorical_accuracy: 0.0274 - val_loss: 4.4191 - val_weighted_categorical_accuracy: 0.0291\n",
      "Epoch 2/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 4.1388 - weighted_categorical_accuracy: 0.0656 - val_loss: 4.0796 - val_weighted_categorical_accuracy: 0.0632\n",
      "Epoch 3/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 3.8232 - weighted_categorical_accuracy: 0.1290 - val_loss: 3.8080 - val_weighted_categorical_accuracy: 0.0976\n",
      "Epoch 4/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 3.5178 - weighted_categorical_accuracy: 0.1828 - val_loss: 3.5443 - val_weighted_categorical_accuracy: 0.1434\n",
      "Epoch 5/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 3.2212 - weighted_categorical_accuracy: 0.2319 - val_loss: 3.3114 - val_weighted_categorical_accuracy: 0.1887\n",
      "Time spent: [s]: 356\n",
      "Evaluating model...\n",
      "39062/39062 [==============================] - 18s 456us/step\n",
      "9788/9788 [==============================] - 5s 466us/step\n",
      "FOLD:  2\n",
      "Training model...\n",
      "Train on 39075 samples, validate on 9775 samples\n",
      "Epoch 1/5\n",
      "39075/39075 [==============================] - 50s 1ms/step - loss: 4.5139 - weighted_categorical_accuracy: 0.0319 - val_loss: 4.3880 - val_weighted_categorical_accuracy: 0.0321\n",
      "Epoch 2/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 4.1054 - weighted_categorical_accuracy: 0.0789 - val_loss: 3.9430 - val_weighted_categorical_accuracy: 0.0880\n",
      "Epoch 3/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 3.7627 - weighted_categorical_accuracy: 0.1288 - val_loss: 3.6823 - val_weighted_categorical_accuracy: 0.1172\n",
      "Epoch 4/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 3.4568 - weighted_categorical_accuracy: 0.1755 - val_loss: 3.4228 - val_weighted_categorical_accuracy: 0.1765\n",
      "Epoch 5/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 3.1888 - weighted_categorical_accuracy: 0.2236 - val_loss: 3.2481 - val_weighted_categorical_accuracy: 0.2009\n",
      "Time spent: [s]: 353\n",
      "Evaluating model...\n",
      "39075/39075 [==============================] - 18s 460us/step\n",
      "9775/9775 [==============================] - 5s 468us/step\n",
      "FOLD:  3\n",
      "Training model...\n",
      "Train on 39101 samples, validate on 9749 samples\n",
      "Epoch 1/5\n",
      "39101/39101 [==============================] - 50s 1ms/step - loss: 4.5044 - weighted_categorical_accuracy: 0.0320 - val_loss: 4.4146 - val_weighted_categorical_accuracy: 0.0419\n",
      "Epoch 2/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 4.0591 - weighted_categorical_accuracy: 0.0811 - val_loss: 4.0055 - val_weighted_categorical_accuracy: 0.0795\n",
      "Epoch 3/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 3.6758 - weighted_categorical_accuracy: 0.1250 - val_loss: 3.5930 - val_weighted_categorical_accuracy: 0.1273\n",
      "Epoch 4/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 3.3729 - weighted_categorical_accuracy: 0.1735 - val_loss: 3.3800 - val_weighted_categorical_accuracy: 0.1732\n",
      "Epoch 5/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 3.1249 - weighted_categorical_accuracy: 0.2251 - val_loss: 3.2142 - val_weighted_categorical_accuracy: 0.2179\n",
      "Time spent: [s]: 346\n",
      "Evaluating model...\n",
      "39101/39101 [==============================] - 18s 457us/step\n",
      "9749/9749 [==============================] - 5s 473us/step\n",
      "FOLD:  4\n",
      "Training model...\n",
      "Train on 39124 samples, validate on 9726 samples\n",
      "Epoch 1/5\n",
      "39124/39124 [==============================] - 50s 1ms/step - loss: 4.4742 - weighted_categorical_accuracy: 0.0285 - val_loss: 4.3073 - val_weighted_categorical_accuracy: 0.0399\n",
      "Epoch 2/5\n",
      "39124/39124 [==============================] - 48s 1ms/step - loss: 4.0727 - weighted_categorical_accuracy: 0.0713 - val_loss: 3.9701 - val_weighted_categorical_accuracy: 0.0683\n",
      "Epoch 3/5\n",
      "39124/39124 [==============================] - 48s 1ms/step - loss: 3.7889 - weighted_categorical_accuracy: 0.1203 - val_loss: 3.7150 - val_weighted_categorical_accuracy: 0.1205\n",
      "Epoch 4/5\n",
      "39124/39124 [==============================] - 48s 1ms/step - loss: 3.5231 - weighted_categorical_accuracy: 0.1702 - val_loss: 3.5074 - val_weighted_categorical_accuracy: 0.1594\n",
      "Epoch 5/5\n",
      "39124/39124 [==============================] - 48s 1ms/step - loss: 3.2659 - weighted_categorical_accuracy: 0.2219 - val_loss: 3.3615 - val_weighted_categorical_accuracy: 0.1919\n",
      "Time spent: [s]: 351\n",
      "Evaluating model...\n",
      "39124/39124 [==============================] - 18s 447us/step\n",
      "9726/9726 [==============================] - 4s 442us/step\n",
      "MODEL:  1\n",
      "FOLD:  0\n",
      "Training model...\n",
      "Train on 39038 samples, validate on 9812 samples\n",
      "Epoch 1/5\n",
      "39038/39038 [==============================] - 50s 1ms/step - loss: 4.4479 - weighted_categorical_accuracy: 0.0315 - val_loss: 4.3250 - val_weighted_categorical_accuracy: 0.0366\n",
      "Epoch 2/5\n",
      "39038/39038 [==============================] - 48s 1ms/step - loss: 3.8918 - weighted_categorical_accuracy: 0.0933 - val_loss: 3.8206 - val_weighted_categorical_accuracy: 0.0983\n",
      "Epoch 3/5\n",
      "39038/39038 [==============================] - 48s 1ms/step - loss: 3.4869 - weighted_categorical_accuracy: 0.1663 - val_loss: 3.4459 - val_weighted_categorical_accuracy: 0.1655\n",
      "Epoch 4/5\n",
      "39038/39038 [==============================] - 48s 1ms/step - loss: 3.1497 - weighted_categorical_accuracy: 0.2327 - val_loss: 3.1896 - val_weighted_categorical_accuracy: 0.2133\n",
      "Epoch 5/5\n",
      "39038/39038 [==============================] - 48s 1ms/step - loss: 2.8724 - weighted_categorical_accuracy: 0.2866 - val_loss: 3.0101 - val_weighted_categorical_accuracy: 0.2422\n",
      "Time spent: [s]: 350\n",
      "Evaluating model...\n",
      "39038/39038 [==============================] - 18s 449us/step\n",
      "9812/9812 [==============================] - 4s 455us/step\n",
      "FOLD:  1\n",
      "Training model...\n",
      "Train on 39062 samples, validate on 9788 samples\n",
      "Epoch 1/5\n",
      "39062/39062 [==============================] - 50s 1ms/step - loss: 4.4786 - weighted_categorical_accuracy: 0.0322 - val_loss: 4.4581 - val_weighted_categorical_accuracy: 0.0403\n",
      "Epoch 2/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 3.9090 - weighted_categorical_accuracy: 0.0947 - val_loss: 3.9218 - val_weighted_categorical_accuracy: 0.0787\n",
      "Epoch 3/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 3.4529 - weighted_categorical_accuracy: 0.1707 - val_loss: 3.5081 - val_weighted_categorical_accuracy: 0.1399\n",
      "Epoch 4/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 3.1035 - weighted_categorical_accuracy: 0.2405 - val_loss: 3.1002 - val_weighted_categorical_accuracy: 0.2264\n",
      "Epoch 5/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 2.8269 - weighted_categorical_accuracy: 0.2945 - val_loss: 2.9522 - val_weighted_categorical_accuracy: 0.2456\n",
      "Time spent: [s]: 343\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39062/39062 [==============================] - 16s 413us/step\n",
      "9788/9788 [==============================] - 4s 418us/step\n",
      "FOLD:  2\n",
      "Training model...\n",
      "Train on 39075 samples, validate on 9775 samples\n",
      "Epoch 1/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 4.4871 - weighted_categorical_accuracy: 0.0332 - val_loss: 4.3524 - val_weighted_categorical_accuracy: 0.0433\n",
      "Epoch 2/5\n",
      "39075/39075 [==============================] - 46s 1ms/step - loss: 3.9489 - weighted_categorical_accuracy: 0.0929 - val_loss: 4.0546 - val_weighted_categorical_accuracy: 0.0698\n",
      "Epoch 3/5\n",
      "39075/39075 [==============================] - 46s 1ms/step - loss: 3.5255 - weighted_categorical_accuracy: 0.1587 - val_loss: 3.4333 - val_weighted_categorical_accuracy: 0.1531\n",
      "Epoch 4/5\n",
      "39075/39075 [==============================] - 46s 1ms/step - loss: 3.1621 - weighted_categorical_accuracy: 0.2321 - val_loss: 3.2579 - val_weighted_categorical_accuracy: 0.1821\n",
      "Epoch 5/5\n",
      "39075/39075 [==============================] - 46s 1ms/step - loss: 2.8708 - weighted_categorical_accuracy: 0.2911 - val_loss: 3.0336 - val_weighted_categorical_accuracy: 0.2470\n",
      "Time spent: [s]: 342\n",
      "Evaluating model...\n",
      "39075/39075 [==============================] - 16s 412us/step\n",
      "9775/9775 [==============================] - 4s 419us/step\n",
      "FOLD:  3\n",
      "Training model...\n",
      "Train on 39101 samples, validate on 9749 samples\n",
      "Epoch 1/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 4.4582 - weighted_categorical_accuracy: 0.0336 - val_loss: 4.2199 - val_weighted_categorical_accuracy: 0.0442\n",
      "Epoch 2/5\n",
      "39101/39101 [==============================] - 47s 1ms/step - loss: 3.9426 - weighted_categorical_accuracy: 0.0905 - val_loss: 3.8727 - val_weighted_categorical_accuracy: 0.0908\n",
      "Epoch 3/5\n",
      "39101/39101 [==============================] - 46s 1ms/step - loss: 3.5598 - weighted_categorical_accuracy: 0.1573 - val_loss: 3.6355 - val_weighted_categorical_accuracy: 0.1237\n",
      "Epoch 4/5\n",
      "39101/39101 [==============================] - 47s 1ms/step - loss: 3.1937 - weighted_categorical_accuracy: 0.2244 - val_loss: 3.3260 - val_weighted_categorical_accuracy: 0.1804\n",
      "Epoch 5/5\n",
      "39101/39101 [==============================] - 46s 1ms/step - loss: 2.8833 - weighted_categorical_accuracy: 0.2812 - val_loss: 3.0134 - val_weighted_categorical_accuracy: 0.2489\n",
      "Time spent: [s]: 336\n",
      "Evaluating model...\n",
      "39101/39101 [==============================] - 16s 412us/step\n",
      "9749/9749 [==============================] - 4s 424us/step\n",
      "FOLD:  4\n",
      "Training model...\n",
      "Train on 39124 samples, validate on 9726 samples\n",
      "Epoch 1/5\n",
      "39124/39124 [==============================] - 49s 1ms/step - loss: 4.4145 - weighted_categorical_accuracy: 0.0398 - val_loss: 4.2470 - val_weighted_categorical_accuracy: 0.0488\n",
      "Epoch 2/5\n",
      "39124/39124 [==============================] - 46s 1ms/step - loss: 3.8223 - weighted_categorical_accuracy: 0.1144 - val_loss: 3.6883 - val_weighted_categorical_accuracy: 0.1201\n",
      "Epoch 3/5\n",
      "39124/39124 [==============================] - 46s 1ms/step - loss: 3.3908 - weighted_categorical_accuracy: 0.1838 - val_loss: 3.3594 - val_weighted_categorical_accuracy: 0.1709\n",
      "Epoch 4/5\n",
      "39124/39124 [==============================] - 46s 1ms/step - loss: 3.0561 - weighted_categorical_accuracy: 0.2484 - val_loss: 3.1677 - val_weighted_categorical_accuracy: 0.2126\n",
      "Epoch 5/5\n",
      "39124/39124 [==============================] - 46s 1ms/step - loss: 2.7849 - weighted_categorical_accuracy: 0.3047 - val_loss: 2.9066 - val_weighted_categorical_accuracy: 0.2823\n",
      "Time spent: [s]: 342\n",
      "Evaluating model...\n",
      "39124/39124 [==============================] - 16s 410us/step\n",
      "9726/9726 [==============================] - 4s 410us/step\n",
      "MODEL:  2\n",
      "FOLD:  0\n",
      "Training model...\n",
      "Train on 39038 samples, validate on 9812 samples\n",
      "Epoch 1/5\n",
      "39038/39038 [==============================] - 48s 1ms/step - loss: 4.4112 - weighted_categorical_accuracy: 0.0423 - val_loss: 4.3043 - val_weighted_categorical_accuracy: 0.0484\n",
      "Epoch 2/5\n",
      "39038/39038 [==============================] - 46s 1ms/step - loss: 3.8442 - weighted_categorical_accuracy: 0.1076 - val_loss: 3.8837 - val_weighted_categorical_accuracy: 0.0777\n",
      "Epoch 3/5\n",
      "39038/39038 [==============================] - 46s 1ms/step - loss: 3.4169 - weighted_categorical_accuracy: 0.1840 - val_loss: 3.4165 - val_weighted_categorical_accuracy: 0.1559\n",
      "Epoch 4/5\n",
      "39038/39038 [==============================] - 46s 1ms/step - loss: 3.0511 - weighted_categorical_accuracy: 0.2593 - val_loss: 3.1274 - val_weighted_categorical_accuracy: 0.2278\n",
      "Epoch 5/5\n",
      "39038/39038 [==============================] - 50s 1ms/step - loss: 2.7540 - weighted_categorical_accuracy: 0.3158 - val_loss: 2.9036 - val_weighted_categorical_accuracy: 0.2715\n",
      "Time spent: [s]: 344\n",
      "Evaluating model...\n",
      "39038/39038 [==============================] - 18s 459us/step\n",
      "9812/9812 [==============================] - 5s 474us/step\n",
      "FOLD:  1\n",
      "Training model...\n",
      "Train on 39062 samples, validate on 9788 samples\n",
      "Epoch 1/5\n",
      "39062/39062 [==============================] - 50s 1ms/step - loss: 4.4060 - weighted_categorical_accuracy: 0.0420 - val_loss: 4.2379 - val_weighted_categorical_accuracy: 0.0543\n",
      "Epoch 2/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 3.8252 - weighted_categorical_accuracy: 0.1234 - val_loss: 3.8229 - val_weighted_categorical_accuracy: 0.0833\n",
      "Epoch 3/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 3.3463 - weighted_categorical_accuracy: 0.2110 - val_loss: 3.3098 - val_weighted_categorical_accuracy: 0.2024\n",
      "Epoch 4/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 2.9502 - weighted_categorical_accuracy: 0.2824 - val_loss: 2.9798 - val_weighted_categorical_accuracy: 0.2537\n",
      "Epoch 5/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 2.6728 - weighted_categorical_accuracy: 0.3381 - val_loss: 2.8250 - val_weighted_categorical_accuracy: 0.2763\n",
      "Time spent: [s]: 349\n",
      "Evaluating model...\n",
      "39062/39062 [==============================] - 18s 462us/step\n",
      "9788/9788 [==============================] - 5s 470us/step\n",
      "FOLD:  2\n",
      "Training model...\n",
      "Train on 39075 samples, validate on 9775 samples\n",
      "Epoch 1/5\n",
      "39075/39075 [==============================] - 54s 1ms/step - loss: 4.4580 - weighted_categorical_accuracy: 0.0323 - val_loss: 4.3582 - val_weighted_categorical_accuracy: 0.0368\n",
      "Epoch 2/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 3.8520 - weighted_categorical_accuracy: 0.1119 - val_loss: 3.8946 - val_weighted_categorical_accuracy: 0.0815\n",
      "Epoch 3/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 3.3847 - weighted_categorical_accuracy: 0.2012 - val_loss: 3.4839 - val_weighted_categorical_accuracy: 0.1576\n",
      "Epoch 4/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 3.0115 - weighted_categorical_accuracy: 0.2707 - val_loss: 3.1210 - val_weighted_categorical_accuracy: 0.2257\n",
      "Epoch 5/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 2.7265 - weighted_categorical_accuracy: 0.3244 - val_loss: 2.9044 - val_weighted_categorical_accuracy: 0.2726\n",
      "Time spent: [s]: 355\n",
      "Evaluating model...\n",
      "39075/39075 [==============================] - 17s 445us/step\n",
      "9775/9775 [==============================] - 4s 453us/step\n",
      "FOLD:  3\n",
      "Training model...\n",
      "Train on 39101 samples, validate on 9749 samples\n",
      "Epoch 1/5\n",
      "39101/39101 [==============================] - 50s 1ms/step - loss: 4.3575 - weighted_categorical_accuracy: 0.0446 - val_loss: 4.1074 - val_weighted_categorical_accuracy: 0.0679\n",
      "Epoch 2/5\n",
      "39101/39101 [==============================] - 50s 1ms/step - loss: 3.7272 - weighted_categorical_accuracy: 0.1424 - val_loss: 3.6088 - val_weighted_categorical_accuracy: 0.1464\n",
      "Epoch 3/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 3.2655 - weighted_categorical_accuracy: 0.2192 - val_loss: 3.2717 - val_weighted_categorical_accuracy: 0.2041\n",
      "Epoch 4/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 2.9060 - weighted_categorical_accuracy: 0.2827 - val_loss: 3.0072 - val_weighted_categorical_accuracy: 0.2517\n",
      "Epoch 5/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 2.6419 - weighted_categorical_accuracy: 0.3349 - val_loss: 2.8106 - val_weighted_categorical_accuracy: 0.2885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent: [s]: 350\n",
      "Evaluating model...\n",
      "39101/39101 [==============================] - 16s 420us/step\n",
      "9749/9749 [==============================] - 4s 431us/step\n",
      "FOLD:  4\n",
      "Training model...\n",
      "Train on 39124 samples, validate on 9726 samples\n",
      "Epoch 1/5\n",
      "39124/39124 [==============================] - 49s 1ms/step - loss: 4.4005 - weighted_categorical_accuracy: 0.0396 - val_loss: 4.1591 - val_weighted_categorical_accuracy: 0.0632\n",
      "Epoch 2/5\n",
      "39124/39124 [==============================] - 49s 1ms/step - loss: 3.8244 - weighted_categorical_accuracy: 0.1156 - val_loss: 3.7091 - val_weighted_categorical_accuracy: 0.1203\n",
      "Epoch 3/5\n",
      "39124/39124 [==============================] - 48s 1ms/step - loss: 3.4048 - weighted_categorical_accuracy: 0.1903 - val_loss: 3.4195 - val_weighted_categorical_accuracy: 0.1717\n",
      "Epoch 4/5\n",
      "39124/39124 [==============================] - 48s 1ms/step - loss: 3.0300 - weighted_categorical_accuracy: 0.2650 - val_loss: 3.2786 - val_weighted_categorical_accuracy: 0.1928\n",
      "Epoch 5/5\n",
      "39124/39124 [==============================] - 48s 1ms/step - loss: 2.7202 - weighted_categorical_accuracy: 0.3308 - val_loss: 2.8591 - val_weighted_categorical_accuracy: 0.2796\n",
      "Time spent: [s]: 348\n",
      "Evaluating model...\n",
      "39124/39124 [==============================] - 18s 464us/step\n",
      "9726/9726 [==============================] - 4s 458us/step\n",
      "MODEL:  3\n",
      "FOLD:  0\n",
      "Training model...\n",
      "Train on 39038 samples, validate on 9812 samples\n",
      "Epoch 1/5\n",
      "39038/39038 [==============================] - 50s 1ms/step - loss: 4.2590 - weighted_categorical_accuracy: 0.0632 - val_loss: 4.1065 - val_weighted_categorical_accuracy: 0.0812\n",
      "Epoch 2/5\n",
      "39038/39038 [==============================] - 53s 1ms/step - loss: 3.3839 - weighted_categorical_accuracy: 0.1943 - val_loss: 3.6078 - val_weighted_categorical_accuracy: 0.1627\n",
      "Epoch 3/5\n",
      "39038/39038 [==============================] - 48s 1ms/step - loss: 2.8425 - weighted_categorical_accuracy: 0.3026 - val_loss: 3.0392 - val_weighted_categorical_accuracy: 0.2417\n",
      "Epoch 4/5\n",
      "39038/39038 [==============================] - 48s 1ms/step - loss: 2.4868 - weighted_categorical_accuracy: 0.3775 - val_loss: 2.7487 - val_weighted_categorical_accuracy: 0.3062\n",
      "Epoch 5/5\n",
      "39038/39038 [==============================] - 49s 1ms/step - loss: 2.2549 - weighted_categorical_accuracy: 0.4253 - val_loss: 2.5213 - val_weighted_categorical_accuracy: 0.3619\n",
      "Time spent: [s]: 347\n",
      "Evaluating model...\n",
      "39038/39038 [==============================] - 19s 479us/step\n",
      "9812/9812 [==============================] - 5s 470us/step\n",
      "FOLD:  1\n",
      "Training model...\n",
      "Train on 39062 samples, validate on 9788 samples\n",
      "Epoch 1/5\n",
      "39062/39062 [==============================] - 50s 1ms/step - loss: 4.2782 - weighted_categorical_accuracy: 0.0555 - val_loss: 4.0616 - val_weighted_categorical_accuracy: 0.0761\n",
      "Epoch 2/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 3.4682 - weighted_categorical_accuracy: 0.1805 - val_loss: 3.4960 - val_weighted_categorical_accuracy: 0.1625\n",
      "Epoch 3/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 2.8988 - weighted_categorical_accuracy: 0.2871 - val_loss: 3.1195 - val_weighted_categorical_accuracy: 0.2381\n",
      "Epoch 4/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 2.5532 - weighted_categorical_accuracy: 0.3561 - val_loss: 2.7325 - val_weighted_categorical_accuracy: 0.3159\n",
      "Epoch 5/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 2.3282 - weighted_categorical_accuracy: 0.4067 - val_loss: 2.6271 - val_weighted_categorical_accuracy: 0.3337\n",
      "Time spent: [s]: 351\n",
      "Evaluating model...\n",
      "39062/39062 [==============================] - 18s 461us/step\n",
      "9788/9788 [==============================] - 5s 473us/step\n",
      "FOLD:  2\n",
      "Training model...\n",
      "Train on 39075 samples, validate on 9775 samples\n",
      "Epoch 1/5\n",
      "39075/39075 [==============================] - 54s 1ms/step - loss: 4.3018 - weighted_categorical_accuracy: 0.0568 - val_loss: 3.9961 - val_weighted_categorical_accuracy: 0.0799\n",
      "Epoch 2/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 3.4392 - weighted_categorical_accuracy: 0.1825 - val_loss: 3.3564 - val_weighted_categorical_accuracy: 0.1812\n",
      "Epoch 3/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 2.8911 - weighted_categorical_accuracy: 0.2839 - val_loss: 2.9945 - val_weighted_categorical_accuracy: 0.2462\n",
      "Epoch 4/5\n",
      "39075/39075 [==============================] - 49s 1ms/step - loss: 2.5545 - weighted_categorical_accuracy: 0.3542 - val_loss: 2.7133 - val_weighted_categorical_accuracy: 0.3117\n",
      "Epoch 5/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 2.3261 - weighted_categorical_accuracy: 0.4053 - val_loss: 2.5925 - val_weighted_categorical_accuracy: 0.3377\n",
      "Time spent: [s]: 348\n",
      "Evaluating model...\n",
      "39075/39075 [==============================] - 18s 465us/step\n",
      "9775/9775 [==============================] - 5s 482us/step\n",
      "FOLD:  3\n",
      "Training model...\n",
      "Train on 39101 samples, validate on 9749 samples\n",
      "Epoch 1/5\n",
      "39101/39101 [==============================] - 50s 1ms/step - loss: 4.2391 - weighted_categorical_accuracy: 0.0610 - val_loss: 3.9639 - val_weighted_categorical_accuracy: 0.0812\n",
      "Epoch 2/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 3.3973 - weighted_categorical_accuracy: 0.1909 - val_loss: 3.4653 - val_weighted_categorical_accuracy: 0.1611\n",
      "Epoch 3/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 2.8623 - weighted_categorical_accuracy: 0.2962 - val_loss: 3.1312 - val_weighted_categorical_accuracy: 0.2320\n",
      "Epoch 4/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 2.5329 - weighted_categorical_accuracy: 0.3627 - val_loss: 2.7757 - val_weighted_categorical_accuracy: 0.3013\n",
      "Epoch 5/5\n",
      "39101/39101 [==============================] - 52s 1ms/step - loss: 2.3115 - weighted_categorical_accuracy: 0.4087 - val_loss: 2.5732 - val_weighted_categorical_accuracy: 0.3391\n",
      "Time spent: [s]: 348\n",
      "Evaluating model...\n",
      "39101/39101 [==============================] - 18s 448us/step\n",
      "9749/9749 [==============================] - 4s 460us/step\n",
      "FOLD:  4\n",
      "Training model...\n",
      "Train on 39124 samples, validate on 9726 samples\n",
      "Epoch 1/5\n",
      "39124/39124 [==============================] - 52s 1ms/step - loss: 4.2249 - weighted_categorical_accuracy: 0.0713 - val_loss: 4.0608 - val_weighted_categorical_accuracy: 0.0702\n",
      "Epoch 2/5\n",
      "39124/39124 [==============================] - 48s 1ms/step - loss: 3.3207 - weighted_categorical_accuracy: 0.2030 - val_loss: 3.4505 - val_weighted_categorical_accuracy: 0.1691\n",
      "Epoch 3/5\n",
      "39124/39124 [==============================] - 48s 1ms/step - loss: 2.8106 - weighted_categorical_accuracy: 0.3001 - val_loss: 3.0888 - val_weighted_categorical_accuracy: 0.2165\n",
      "Epoch 4/5\n",
      "39124/39124 [==============================] - 48s 1ms/step - loss: 2.4761 - weighted_categorical_accuracy: 0.3731 - val_loss: 2.7811 - val_weighted_categorical_accuracy: 0.2852\n",
      "Epoch 5/5\n",
      "39124/39124 [==============================] - 48s 1ms/step - loss: 2.2501 - weighted_categorical_accuracy: 0.4249 - val_loss: 2.7102 - val_weighted_categorical_accuracy: 0.3245\n",
      "Time spent: [s]: 349\n",
      "Evaluating model...\n",
      "39124/39124 [==============================] - 18s 461us/step\n",
      "9726/9726 [==============================] - 4s 454us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.21454258, 0.26815721, 0.29769311, 0.36750228]),\n",
       " array([3.26383438, 2.98318697, 2.86056535, 2.60486161]),\n",
       " array([0.20426393, 0.25320009, 0.27769951, 0.33937573]),\n",
       " array([351.0089686, 342.4711168, 349.0196766, 348.5920672]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_step = MyTuningStep()\n",
    "tuning_step.train_tuning_step_with_kfolds(train_params=train_params, list_of_hyperparams=list_of_hyperparams, data=data_2, labels=labels_2, labels_weights=labels_2_weights, k_folds=k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy [%]:  [21.45425816 26.81572141 29.76931081 36.75022803]\n",
      "Eval accuracy [%]:  [20.42639276 25.32000942 27.769951   33.93757293]\n",
      "Bias [%]:  [78.54574184 73.18427859 70.23068919 63.24977197]\n",
      "Variance [%]:  [1.0278654  1.49571199 1.99935981 2.8126551 ]\n"
     ]
    }
   ],
   "source": [
    "tuning_step.print_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2st set of hyperparams\n",
    "So the best configuration was the set 3, which is the most complex one. So let's try some more complex  sets similar to that one, to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_hyperparams = [\n",
    "                {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 512,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 256,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_2.shape[1]\n",
    "                    },\n",
    "                {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 1024,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 512,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_2.shape[1]\n",
    "                    },\n",
    "                {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 2048,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 1024,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_2.shape[1]\n",
    "                    },\n",
    "                {\n",
    "                    \"LSTM_DROPOUT\" : 0,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0,\n",
    "                    \"1_FC_SIZE\" : 1024,\n",
    "                    \"1_FC_DROPOUT\" : 0,\n",
    "                    \"2_FC_SIZE\" : 1024,\n",
    "                    \"2_FC_DROPOUT\" : 0,\n",
    "                    \"FINAL_SIZE\" : labels_2.shape[1]\n",
    "                    },\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL:  0\n",
      "FOLD:  0\n",
      "Training model...\n",
      "Train on 39038 samples, validate on 9812 samples\n",
      "Epoch 1/5\n",
      "39038/39038 [==============================] - 51s 1ms/step - loss: 3.7904 - weighted_categorical_accuracy: 0.1314 - val_loss: 3.4212 - val_weighted_categorical_accuracy: 0.1689\n",
      "Epoch 2/5\n",
      "39038/39038 [==============================] - 49s 1ms/step - loss: 2.6707 - weighted_categorical_accuracy: 0.3286 - val_loss: 2.8791 - val_weighted_categorical_accuracy: 0.2815\n",
      "Epoch 3/5\n",
      "39038/39038 [==============================] - 49s 1ms/step - loss: 2.2446 - weighted_categorical_accuracy: 0.4184 - val_loss: 2.5582 - val_weighted_categorical_accuracy: 0.3492\n",
      "Epoch 4/5\n",
      "39038/39038 [==============================] - 49s 1ms/step - loss: 2.0138 - weighted_categorical_accuracy: 0.4716 - val_loss: 2.4088 - val_weighted_categorical_accuracy: 0.3823\n",
      "Epoch 5/5\n",
      "39038/39038 [==============================] - 49s 1ms/step - loss: 1.8616 - weighted_categorical_accuracy: 0.5063 - val_loss: 2.2986 - val_weighted_categorical_accuracy: 0.4035\n",
      "Time spent: [s]: 344\n",
      "Evaluating model...\n",
      "39038/39038 [==============================] - 19s 476us/step\n",
      "9812/9812 [==============================] - 5s 486us/step\n",
      "FOLD:  1\n",
      "Training model...\n",
      "Train on 39062 samples, validate on 9788 samples\n",
      "Epoch 1/5\n",
      "39062/39062 [==============================] - 55s 1ms/step - loss: 3.8405 - weighted_categorical_accuracy: 0.1236 - val_loss: 3.4328 - val_weighted_categorical_accuracy: 0.1758\n",
      "Epoch 2/5\n",
      "39062/39062 [==============================] - 49s 1ms/step - loss: 2.7112 - weighted_categorical_accuracy: 0.3205 - val_loss: 2.8733 - val_weighted_categorical_accuracy: 0.2816\n",
      "Epoch 3/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 2.2627 - weighted_categorical_accuracy: 0.4161 - val_loss: 2.6492 - val_weighted_categorical_accuracy: 0.3192\n",
      "Epoch 4/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 2.0267 - weighted_categorical_accuracy: 0.4702 - val_loss: 2.3892 - val_weighted_categorical_accuracy: 0.3826\n",
      "Epoch 5/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 1.8700 - weighted_categorical_accuracy: 0.5072 - val_loss: 2.3108 - val_weighted_categorical_accuracy: 0.4059\n",
      "Time spent: [s]: 356\n",
      "Evaluating model...\n",
      "39062/39062 [==============================] - 18s 457us/step\n",
      "9788/9788 [==============================] - 5s 467us/step\n",
      "FOLD:  2\n",
      "Training model...\n",
      "Train on 39075 samples, validate on 9775 samples\n",
      "Epoch 1/5\n",
      "39075/39075 [==============================] - 51s 1ms/step - loss: 3.7689 - weighted_categorical_accuracy: 0.1301 - val_loss: 3.5461 - val_weighted_categorical_accuracy: 0.1664\n",
      "Epoch 2/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 2.6322 - weighted_categorical_accuracy: 0.3312 - val_loss: 2.8806 - val_weighted_categorical_accuracy: 0.2825\n",
      "Epoch 3/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 2.2103 - weighted_categorical_accuracy: 0.4244 - val_loss: 2.6315 - val_weighted_categorical_accuracy: 0.3376\n",
      "Epoch 4/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 1.9843 - weighted_categorical_accuracy: 0.4786 - val_loss: 2.4790 - val_weighted_categorical_accuracy: 0.3717\n",
      "Epoch 5/5\n",
      "39075/39075 [==============================] - 48s 1ms/step - loss: 1.8410 - weighted_categorical_accuracy: 0.5106 - val_loss: 2.2811 - val_weighted_categorical_accuracy: 0.4158\n",
      "Time spent: [s]: 348\n",
      "Evaluating model...\n",
      "39075/39075 [==============================] - 18s 459us/step\n",
      "9775/9775 [==============================] - 5s 467us/step\n",
      "FOLD:  3\n",
      "Training model...\n",
      "Train on 39101 samples, validate on 9749 samples\n",
      "Epoch 1/5\n",
      "39101/39101 [==============================] - 50s 1ms/step - loss: 3.8735 - weighted_categorical_accuracy: 0.1171 - val_loss: 3.6396 - val_weighted_categorical_accuracy: 0.1445\n",
      "Epoch 2/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 2.7190 - weighted_categorical_accuracy: 0.3163 - val_loss: 2.9698 - val_weighted_categorical_accuracy: 0.2617\n",
      "Epoch 3/5\n",
      "39101/39101 [==============================] - 50s 1ms/step - loss: 2.2622 - weighted_categorical_accuracy: 0.4128 - val_loss: 2.6059 - val_weighted_categorical_accuracy: 0.3380\n",
      "Epoch 4/5\n",
      "39101/39101 [==============================] - 49s 1ms/step - loss: 2.0239 - weighted_categorical_accuracy: 0.4712 - val_loss: 2.4820 - val_weighted_categorical_accuracy: 0.3692\n",
      "Epoch 5/5\n",
      "39101/39101 [==============================] - 49s 1ms/step - loss: 1.8714 - weighted_categorical_accuracy: 0.5038 - val_loss: 2.3048 - val_weighted_categorical_accuracy: 0.4075\n",
      "Time spent: [s]: 347\n",
      "Evaluating model...\n",
      "39101/39101 [==============================] - 18s 469us/step\n",
      "9749/9749 [==============================] - 5s 483us/step\n",
      "FOLD:  4\n",
      "Training model...\n",
      "Train on 39124 samples, validate on 9726 samples\n",
      "Epoch 1/5\n",
      "39124/39124 [==============================] - 51s 1ms/step - loss: 3.7897 - weighted_categorical_accuracy: 0.1346 - val_loss: 3.4804 - val_weighted_categorical_accuracy: 0.1759\n",
      "Epoch 2/5\n",
      "39124/39124 [==============================] - 49s 1ms/step - loss: 2.6584 - weighted_categorical_accuracy: 0.3358 - val_loss: 2.8725 - val_weighted_categorical_accuracy: 0.2852\n",
      "Epoch 3/5\n",
      "39124/39124 [==============================] - 49s 1ms/step - loss: 2.2130 - weighted_categorical_accuracy: 0.4316 - val_loss: 2.5919 - val_weighted_categorical_accuracy: 0.3435\n",
      "Epoch 4/5\n",
      "39124/39124 [==============================] - 53s 1ms/step - loss: 1.9744 - weighted_categorical_accuracy: 0.4862 - val_loss: 2.3793 - val_weighted_categorical_accuracy: 0.3945\n",
      "Epoch 5/5\n",
      "39124/39124 [==============================] - 48s 1ms/step - loss: 1.8231 - weighted_categorical_accuracy: 0.5203 - val_loss: 2.3300 - val_weighted_categorical_accuracy: 0.4072\n",
      "Time spent: [s]: 353\n",
      "Evaluating model...\n",
      "39124/39124 [==============================] - 17s 423us/step\n",
      "9726/9726 [==============================] - 4s 418us/step\n",
      "MODEL:  1\n",
      "FOLD:  0\n",
      "Training model...\n",
      "Train on 39038 samples, validate on 9812 samples\n",
      "Epoch 1/5\n",
      "39038/39038 [==============================] - 50s 1ms/step - loss: 3.5069 - weighted_categorical_accuracy: 0.1801 - val_loss: 3.2937 - val_weighted_categorical_accuracy: 0.2139\n",
      "Epoch 2/5\n",
      "39038/39038 [==============================] - 47s 1ms/step - loss: 2.3902 - weighted_categorical_accuracy: 0.3869 - val_loss: 2.7040 - val_weighted_categorical_accuracy: 0.3252\n",
      "Epoch 3/5\n",
      "39038/39038 [==============================] - 47s 1ms/step - loss: 2.0260 - weighted_categorical_accuracy: 0.4693 - val_loss: 2.4939 - val_weighted_categorical_accuracy: 0.3643\n",
      "Epoch 4/5\n",
      "39038/39038 [==============================] - 48s 1ms/step - loss: 1.8238 - weighted_categorical_accuracy: 0.5167 - val_loss: 2.5432 - val_weighted_categorical_accuracy: 0.3577\n",
      "Epoch 5/5\n",
      "39038/39038 [==============================] - 48s 1ms/step - loss: 1.6767 - weighted_categorical_accuracy: 0.5528 - val_loss: 2.3621 - val_weighted_categorical_accuracy: 0.3962\n",
      "Time spent: [s]: 341\n",
      "Evaluating model...\n",
      "39038/39038 [==============================] - 17s 425us/step\n",
      "9812/9812 [==============================] - 4s 438us/step\n",
      "FOLD:  1\n",
      "Training model...\n",
      "Train on 39062 samples, validate on 9788 samples\n",
      "Epoch 1/5\n",
      "39062/39062 [==============================] - 49s 1ms/step - loss: 3.4861 - weighted_categorical_accuracy: 0.1876 - val_loss: 3.5322 - val_weighted_categorical_accuracy: 0.2018\n",
      "Epoch 2/5\n",
      "39062/39062 [==============================] - 47s 1ms/step - loss: 2.3761 - weighted_categorical_accuracy: 0.3916 - val_loss: 2.9168 - val_weighted_categorical_accuracy: 0.2962\n",
      "Epoch 3/5\n",
      "39062/39062 [==============================] - 48s 1ms/step - loss: 2.0135 - weighted_categorical_accuracy: 0.4709 - val_loss: 2.4800 - val_weighted_categorical_accuracy: 0.3753\n",
      "Epoch 4/5\n",
      "39062/39062 [==============================] - 47s 1ms/step - loss: 1.8089 - weighted_categorical_accuracy: 0.5183 - val_loss: 2.5020 - val_weighted_categorical_accuracy: 0.3680\n",
      "Epoch 5/5\n",
      "39062/39062 [==============================] - 47s 1ms/step - loss: 1.6677 - weighted_categorical_accuracy: 0.5523 - val_loss: 2.2730 - val_weighted_categorical_accuracy: 0.4224\n",
      "Time spent: [s]: 341\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39062/39062 [==============================] - 16s 416us/step\n",
      "9788/9788 [==============================] - 4s 432us/step\n",
      "FOLD:  2\n",
      "Training model...\n",
      "Train on 39075 samples, validate on 9775 samples\n",
      "Epoch 1/5\n",
      "39075/39075 [==============================] - 55s 1ms/step - loss: 3.5492 - weighted_categorical_accuracy: 0.1719 - val_loss: 3.3181 - val_weighted_categorical_accuracy: 0.2160\n",
      "Epoch 2/5\n",
      "39075/39075 [==============================] - 49s 1ms/step - loss: 2.4048 - weighted_categorical_accuracy: 0.3805 - val_loss: 2.8384 - val_weighted_categorical_accuracy: 0.3011\n",
      "Epoch 3/5\n",
      "39075/39075 [==============================] - 49s 1ms/step - loss: 2.0309 - weighted_categorical_accuracy: 0.4662 - val_loss: 2.6163 - val_weighted_categorical_accuracy: 0.3431\n",
      "Epoch 4/5\n",
      "39075/39075 [==============================] - 49s 1ms/step - loss: 1.8251 - weighted_categorical_accuracy: 0.5171 - val_loss: 2.4118 - val_weighted_categorical_accuracy: 0.3863\n",
      "Epoch 5/5\n",
      "39075/39075 [==============================] - 49s 1ms/step - loss: 1.6884 - weighted_categorical_accuracy: 0.5507 - val_loss: 2.3241 - val_weighted_categorical_accuracy: 0.4171\n",
      "Time spent: [s]: 349\n",
      "Evaluating model...\n",
      "39075/39075 [==============================] - 18s 469us/step\n",
      "9775/9775 [==============================] - 5s 477us/step\n",
      "FOLD:  3\n",
      "Training model...\n",
      "Train on 39101 samples, validate on 9749 samples\n",
      "Epoch 1/5\n",
      "39101/39101 [==============================] - 55s 1ms/step - loss: 3.4818 - weighted_categorical_accuracy: 0.1871 - val_loss: 3.2584 - val_weighted_categorical_accuracy: 0.2301\n",
      "Epoch 2/5\n",
      "39101/39101 [==============================] - 49s 1ms/step - loss: 2.3480 - weighted_categorical_accuracy: 0.3941 - val_loss: 2.7675 - val_weighted_categorical_accuracy: 0.3195\n",
      "Epoch 3/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 2.0013 - weighted_categorical_accuracy: 0.4718 - val_loss: 2.6802 - val_weighted_categorical_accuracy: 0.3332\n",
      "Epoch 4/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 1.8058 - weighted_categorical_accuracy: 0.5222 - val_loss: 2.4259 - val_weighted_categorical_accuracy: 0.3912\n",
      "Epoch 5/5\n",
      "39101/39101 [==============================] - 48s 1ms/step - loss: 1.6712 - weighted_categorical_accuracy: 0.5527 - val_loss: 2.3809 - val_weighted_categorical_accuracy: 0.4021\n",
      "Time spent: [s]: 348\n",
      "Evaluating model...\n",
      "39101/39101 [==============================] - 17s 447us/step\n",
      "9749/9749 [==============================] - 4s 461us/step\n",
      "FOLD:  4\n",
      "Training model...\n",
      "Train on 39124 samples, validate on 9726 samples\n",
      "Epoch 1/5\n",
      "39124/39124 [==============================] - 50s 1ms/step - loss: 3.4880 - weighted_categorical_accuracy: 0.1816 - val_loss: 3.2847 - val_weighted_categorical_accuracy: 0.2136\n",
      "Epoch 2/5\n",
      "39124/39124 [==============================] - 48s 1ms/step - loss: 2.4024 - weighted_categorical_accuracy: 0.3807 - val_loss: 2.8601 - val_weighted_categorical_accuracy: 0.2896\n",
      "Epoch 3/5\n",
      "39124/39124 [==============================] - 50s 1ms/step - loss: 2.0429 - weighted_categorical_accuracy: 0.4654 - val_loss: 2.6910 - val_weighted_categorical_accuracy: 0.3427\n",
      "Epoch 4/5\n",
      "39124/39124 [==============================] - 49s 1ms/step - loss: 1.8285 - weighted_categorical_accuracy: 0.5155 - val_loss: 2.4226 - val_weighted_categorical_accuracy: 0.3811\n",
      "Epoch 5/5\n",
      "39124/39124 [==============================] - 49s 1ms/step - loss: 1.6851 - weighted_categorical_accuracy: 0.5515 - val_loss: 2.4455 - val_weighted_categorical_accuracy: 0.3848\n",
      "Time spent: [s]: 346\n",
      "Evaluating model...\n",
      "39124/39124 [==============================] - 18s 465us/step\n",
      "9726/9726 [==============================] - 4s 461us/step\n",
      "MODEL:  2\n",
      "FOLD:  0\n",
      "Training model...\n",
      "Train on 39038 samples, validate on 9812 samples\n",
      "Epoch 1/5\n",
      "39038/39038 [==============================] - 52s 1ms/step - loss: 3.3548 - weighted_categorical_accuracy: 0.2160 - val_loss: 3.1001 - val_weighted_categorical_accuracy: 0.2547\n",
      "Epoch 2/5\n",
      "39038/39038 [==============================] - 50s 1ms/step - loss: 2.2543 - weighted_categorical_accuracy: 0.4133 - val_loss: 2.6801 - val_weighted_categorical_accuracy: 0.3363\n",
      "Epoch 3/5\n",
      "39038/39038 [==============================] - 50s 1ms/step - loss: 1.9219 - weighted_categorical_accuracy: 0.4911 - val_loss: 2.5671 - val_weighted_categorical_accuracy: 0.3566\n",
      "Epoch 4/5\n",
      "39038/39038 [==============================] - 53s 1ms/step - loss: 1.7187 - weighted_categorical_accuracy: 0.5374 - val_loss: 2.5307 - val_weighted_categorical_accuracy: 0.3702\n",
      "Epoch 5/5\n",
      "39038/39038 [==============================] - 50s 1ms/step - loss: 1.5643 - weighted_categorical_accuracy: 0.5739 - val_loss: 2.4450 - val_weighted_categorical_accuracy: 0.3848\n",
      "Time spent: [s]: 354\n",
      "Evaluating model...\n",
      "39038/39038 [==============================] - 18s 470us/step\n",
      "9812/9812 [==============================] - 5s 477us/step\n",
      "FOLD:  1\n",
      "Training model...\n",
      "Train on 39062 samples, validate on 9788 samples\n",
      "Epoch 1/5\n",
      "39062/39062 [==============================] - 54s 1ms/step - loss: 3.3166 - weighted_categorical_accuracy: 0.2157 - val_loss: 3.1300 - val_weighted_categorical_accuracy: 0.2545\n",
      "Epoch 2/5\n",
      "39062/39062 [==============================] - 51s 1ms/step - loss: 2.2665 - weighted_categorical_accuracy: 0.4124 - val_loss: 2.7200 - val_weighted_categorical_accuracy: 0.3216\n",
      "Epoch 3/5\n",
      "39062/39062 [==============================] - 50s 1ms/step - loss: 1.9347 - weighted_categorical_accuracy: 0.4901 - val_loss: 2.6550 - val_weighted_categorical_accuracy: 0.3386\n",
      "Epoch 4/5\n",
      "39062/39062 [==============================] - 50s 1ms/step - loss: 1.7298 - weighted_categorical_accuracy: 0.5374 - val_loss: 2.5780 - val_weighted_categorical_accuracy: 0.3494\n",
      "Epoch 5/5\n",
      "39062/39062 [==============================] - 50s 1ms/step - loss: 1.5709 - weighted_categorical_accuracy: 0.5766 - val_loss: 2.5120 - val_weighted_categorical_accuracy: 0.3605\n",
      "Time spent: [s]: 353\n",
      "Evaluating model...\n",
      "39062/39062 [==============================] - 19s 475us/step\n",
      "9788/9788 [==============================] - 5s 490us/step\n",
      "FOLD:  2\n",
      "Training model...\n",
      "Train on 39075 samples, validate on 9775 samples\n",
      "Epoch 1/5\n",
      "39075/39075 [==============================] - 54s 1ms/step - loss: 3.3146 - weighted_categorical_accuracy: 0.2125 - val_loss: 3.0889 - val_weighted_categorical_accuracy: 0.2614\n",
      "Epoch 2/5\n",
      "39075/39075 [==============================] - 60s 2ms/step - loss: 2.2911 - weighted_categorical_accuracy: 0.4029 - val_loss: 2.7052 - val_weighted_categorical_accuracy: 0.3339\n",
      "Epoch 3/5\n",
      "39075/39075 [==============================] - 60s 2ms/step - loss: 1.9443 - weighted_categorical_accuracy: 0.4826 - val_loss: 2.4850 - val_weighted_categorical_accuracy: 0.3699\n",
      "Epoch 4/5\n",
      "39075/39075 [==============================] - 55s 1ms/step - loss: 1.7307 - weighted_categorical_accuracy: 0.5388 - val_loss: 2.3801 - val_weighted_categorical_accuracy: 0.3873\n",
      "Epoch 5/5\n",
      "39075/39075 [==============================] - 55s 1ms/step - loss: 1.5635 - weighted_categorical_accuracy: 0.5777 - val_loss: 2.3655 - val_weighted_categorical_accuracy: 0.4010\n",
      "Time spent: [s]: 379\n",
      "Evaluating model...\n",
      "39075/39075 [==============================] - 20s 514us/step\n",
      "9775/9775 [==============================] - 6s 596us/step\n",
      "FOLD:  3\n",
      "Training model...\n",
      "Train on 39101 samples, validate on 9749 samples\n",
      "Epoch 1/5\n",
      "39101/39101 [==============================] - 59s 1ms/step - loss: 3.3447 - weighted_categorical_accuracy: 0.2118 - val_loss: 3.0505 - val_weighted_categorical_accuracy: 0.2656\n",
      "Epoch 2/5\n",
      "39101/39101 [==============================] - 57s 1ms/step - loss: 2.2513 - weighted_categorical_accuracy: 0.4129 - val_loss: 2.7035 - val_weighted_categorical_accuracy: 0.3243\n",
      "Epoch 3/5\n",
      "39101/39101 [==============================] - 56s 1ms/step - loss: 1.9221 - weighted_categorical_accuracy: 0.4920 - val_loss: 2.6199 - val_weighted_categorical_accuracy: 0.3430\n",
      "Epoch 4/5\n",
      "39101/39101 [==============================] - 56s 1ms/step - loss: 1.7128 - weighted_categorical_accuracy: 0.5430 - val_loss: 2.5987 - val_weighted_categorical_accuracy: 0.3505\n",
      "Epoch 5/5\n",
      "39101/39101 [==============================] - 58s 1ms/step - loss: 1.5527 - weighted_categorical_accuracy: 0.5824 - val_loss: 2.6114 - val_weighted_categorical_accuracy: 0.3547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent: [s]: 381\n",
      "Evaluating model...\n",
      "39101/39101 [==============================] - 20s 514us/step\n",
      "9749/9749 [==============================] - 5s 490us/step\n",
      "FOLD:  4\n",
      "Training model...\n",
      "Train on 39124 samples, validate on 9726 samples\n",
      "Epoch 1/5\n",
      "39124/39124 [==============================] - 61s 2ms/step - loss: 3.3350 - weighted_categorical_accuracy: 0.2137 - val_loss: 3.0164 - val_weighted_categorical_accuracy: 0.2626\n",
      "Epoch 2/5\n",
      "39124/39124 [==============================] - 50s 1ms/step - loss: 2.2654 - weighted_categorical_accuracy: 0.4122 - val_loss: 2.7240 - val_weighted_categorical_accuracy: 0.3293\n",
      "Epoch 3/5\n",
      "39124/39124 [==============================] - 51s 1ms/step - loss: 1.9288 - weighted_categorical_accuracy: 0.4890 - val_loss: 2.4415 - val_weighted_categorical_accuracy: 0.3782\n",
      "Epoch 4/5\n",
      "39124/39124 [==============================] - 50s 1ms/step - loss: 1.7159 - weighted_categorical_accuracy: 0.5410 - val_loss: 2.6218 - val_weighted_categorical_accuracy: 0.3451\n",
      "Epoch 5/5\n",
      "39124/39124 [==============================] - 50s 1ms/step - loss: 1.5612 - weighted_categorical_accuracy: 0.5808 - val_loss: 2.4532 - val_weighted_categorical_accuracy: 0.3788\n",
      "Time spent: [s]: 361\n",
      "Evaluating model...\n",
      "39124/39124 [==============================] - 18s 470us/step\n",
      "9726/9726 [==============================] - 5s 466us/step\n",
      "MODEL:  3\n",
      "FOLD:  0\n",
      "Training model...\n",
      "Train on 39038 samples, validate on 9812 samples\n",
      "Epoch 1/5\n",
      "39038/39038 [==============================] - 51s 1ms/step - loss: 3.4148 - weighted_categorical_accuracy: 0.2003 - val_loss: 3.1166 - val_weighted_categorical_accuracy: 0.2579\n",
      "Epoch 2/5\n",
      "39038/39038 [==============================] - 49s 1ms/step - loss: 2.2975 - weighted_categorical_accuracy: 0.4061 - val_loss: 2.7006 - val_weighted_categorical_accuracy: 0.3208\n",
      "Epoch 3/5\n",
      "39038/39038 [==============================] - 49s 1ms/step - loss: 1.9365 - weighted_categorical_accuracy: 0.4874 - val_loss: 2.5961 - val_weighted_categorical_accuracy: 0.3398\n",
      "Epoch 4/5\n",
      "39038/39038 [==============================] - 53s 1ms/step - loss: 1.7272 - weighted_categorical_accuracy: 0.5364 - val_loss: 2.6701 - val_weighted_categorical_accuracy: 0.3405\n",
      "Epoch 5/5\n",
      "39038/39038 [==============================] - 49s 1ms/step - loss: 1.5660 - weighted_categorical_accuracy: 0.5748 - val_loss: 2.4713 - val_weighted_categorical_accuracy: 0.3766\n",
      "Time spent: [s]: 357\n",
      "Evaluating model...\n",
      "39038/39038 [==============================] - 18s 449us/step\n",
      "9812/9812 [==============================] - 5s 464us/step\n",
      "FOLD:  1\n",
      "Training model...\n",
      "Train on 39062 samples, validate on 9788 samples\n",
      "Epoch 1/5\n",
      "39062/39062 [==============================] - 51s 1ms/step - loss: 3.3556 - weighted_categorical_accuracy: 0.2122 - val_loss: 3.0329 - val_weighted_categorical_accuracy: 0.2675\n",
      "Epoch 2/5\n",
      "39062/39062 [==============================] - 49s 1ms/step - loss: 2.2462 - weighted_categorical_accuracy: 0.4207 - val_loss: 2.6417 - val_weighted_categorical_accuracy: 0.3318\n",
      "Epoch 3/5\n",
      "39062/39062 [==============================] - 49s 1ms/step - loss: 1.9107 - weighted_categorical_accuracy: 0.4962 - val_loss: 2.4524 - val_weighted_categorical_accuracy: 0.3814\n",
      "Epoch 4/5\n",
      "39062/39062 [==============================] - 49s 1ms/step - loss: 1.7040 - weighted_categorical_accuracy: 0.5430 - val_loss: 2.3840 - val_weighted_categorical_accuracy: 0.3921\n",
      "Epoch 5/5\n",
      "39062/39062 [==============================] - 49s 1ms/step - loss: 1.5487 - weighted_categorical_accuracy: 0.5860 - val_loss: 2.4330 - val_weighted_categorical_accuracy: 0.3927\n",
      "Time spent: [s]: 348\n",
      "Evaluating model...\n",
      "39062/39062 [==============================] - 17s 448us/step\n",
      "9788/9788 [==============================] - 4s 456us/step\n",
      "FOLD:  2\n",
      "Training model...\n",
      "Train on 39075 samples, validate on 9775 samples\n",
      "Epoch 1/5\n",
      "39075/39075 [==============================] - 51s 1ms/step - loss: 3.4055 - weighted_categorical_accuracy: 0.2021 - val_loss: 3.1768 - val_weighted_categorical_accuracy: 0.2303\n",
      "Epoch 2/5\n",
      "39075/39075 [==============================] - 49s 1ms/step - loss: 2.3004 - weighted_categorical_accuracy: 0.4013 - val_loss: 2.7810 - val_weighted_categorical_accuracy: 0.3220\n",
      "Epoch 3/5\n",
      "39075/39075 [==============================] - 55s 1ms/step - loss: 1.9564 - weighted_categorical_accuracy: 0.4815 - val_loss: 2.6264 - val_weighted_categorical_accuracy: 0.3357\n",
      "Epoch 4/5\n",
      "39075/39075 [==============================] - 57s 1ms/step - loss: 1.7366 - weighted_categorical_accuracy: 0.5350 - val_loss: 2.5296 - val_weighted_categorical_accuracy: 0.3659\n",
      "Epoch 5/5\n",
      "39075/39075 [==============================] - 53s 1ms/step - loss: 1.5713 - weighted_categorical_accuracy: 0.5736 - val_loss: 2.5263 - val_weighted_categorical_accuracy: 0.3671\n",
      "Time spent: [s]: 367\n",
      "Evaluating model...\n",
      "39075/39075 [==============================] - 18s 469us/step\n",
      "9775/9775 [==============================] - 5s 480us/step\n",
      "FOLD:  3\n",
      "Training model...\n",
      "Train on 39101 samples, validate on 9749 samples\n",
      "Epoch 1/5\n",
      "39101/39101 [==============================] - 51s 1ms/step - loss: 3.4134 - weighted_categorical_accuracy: 0.1979 - val_loss: 3.3577 - val_weighted_categorical_accuracy: 0.2270\n",
      "Epoch 2/5\n",
      "39101/39101 [==============================] - 50s 1ms/step - loss: 2.2911 - weighted_categorical_accuracy: 0.4039 - val_loss: 2.9661 - val_weighted_categorical_accuracy: 0.3010\n",
      "Epoch 3/5\n",
      "39101/39101 [==============================] - 50s 1ms/step - loss: 1.9422 - weighted_categorical_accuracy: 0.4842 - val_loss: 2.7103 - val_weighted_categorical_accuracy: 0.3353\n",
      "Epoch 4/5\n",
      "39101/39101 [==============================] - 49s 1ms/step - loss: 1.7359 - weighted_categorical_accuracy: 0.5358 - val_loss: 2.4672 - val_weighted_categorical_accuracy: 0.3743\n",
      "Epoch 5/5\n",
      "39101/39101 [==============================] - 51s 1ms/step - loss: 1.5853 - weighted_categorical_accuracy: 0.5720 - val_loss: 2.7108 - val_weighted_categorical_accuracy: 0.3557\n",
      "Time spent: [s]: 355\n",
      "Evaluating model...\n",
      "39101/39101 [==============================] - 18s 467us/step\n",
      "9749/9749 [==============================] - 5s 467us/step\n",
      "FOLD:  4\n",
      "Training model...\n",
      "Train on 39124 samples, validate on 9726 samples\n",
      "Epoch 1/5\n",
      "39124/39124 [==============================] - 53s 1ms/step - loss: 3.5144 - weighted_categorical_accuracy: 0.1842 - val_loss: 3.2776 - val_weighted_categorical_accuracy: 0.2321\n",
      "Epoch 2/5\n",
      "39124/39124 [==============================] - 49s 1ms/step - loss: 2.3457 - weighted_categorical_accuracy: 0.3934 - val_loss: 2.8086 - val_weighted_categorical_accuracy: 0.3149\n",
      "Epoch 3/5\n",
      "39124/39124 [==============================] - 49s 1ms/step - loss: 1.9675 - weighted_categorical_accuracy: 0.4796 - val_loss: 2.7104 - val_weighted_categorical_accuracy: 0.3308\n",
      "Epoch 4/5\n",
      "39124/39124 [==============================] - 49s 1ms/step - loss: 1.7427 - weighted_categorical_accuracy: 0.5304 - val_loss: 2.4587 - val_weighted_categorical_accuracy: 0.3774\n",
      "Epoch 5/5\n",
      "39124/39124 [==============================] - 50s 1ms/step - loss: 1.5763 - weighted_categorical_accuracy: 0.5748 - val_loss: 2.4740 - val_weighted_categorical_accuracy: 0.3750\n",
      "Time spent: [s]: 346\n",
      "Evaluating model...\n",
      "39124/39124 [==============================] - 18s 469us/step\n",
      "9726/9726 [==============================] - 5s 492us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.46531162, 0.48588869, 0.4682105 , 0.46656374]),\n",
       " array([2.30505046, 2.35713613, 2.47741552, 2.52307179]),\n",
       " array([0.40796605, 0.40452501, 0.3759766 , 0.37341348]),\n",
       " array([349.5790434, 344.8153834, 365.3953644, 354.5131678]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_step.train_tuning_step_with_kfolds(train_params=train_params, list_of_hyperparams=list_of_hyperparams, data=data_2, labels=labels_2, labels_weights=labels_2_weights, k_folds=k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy [%]:  [46.53116224 48.58886913 46.82104984 46.65637443]\n",
      "Eval accuracy [%]:  [40.79660495 40.45250121 37.5976603  37.34134795]\n",
      "Bias [%]:  [53.46883776 51.41113087 53.17895016 53.34362557]\n",
      "Variance [%]:  [5.73455729 8.13636792 9.22338954 9.31502648]\n"
     ]
    }
   ],
   "source": [
    "tuning_step.print_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final set of hyperparams\n",
    "So the set 1 is the one with the lower Bias, but it also has some variance. We could keep looking for better hyperparameters, but just to keep on to finish the challenge before the deadline, let's keep with this values, but training more epochs and adding some dropout to reduce variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams =       {\n",
    "                    \"LSTM_DROPOUT\" : 0.1,\n",
    "                    \"LSTM_RECURRENT_DROPOUT\" : 0.1,\n",
    "                    \"1_FC_SIZE\" : 1024,\n",
    "                    \"1_FC_DROPOUT\" : 0.5,\n",
    "                    \"2_FC_SIZE\" : 512,\n",
    "                    \"2_FC_DROPOUT\" : 0.5,\n",
    "                    \"FINAL_SIZE\" : labels_2.shape[1]\n",
    "                    }\n",
    "\n",
    "train_params = {\n",
    "    \"BATCH_SIZE\": 1024,\n",
    "    \"NUM_EPOCHS\": 20\n",
    "}\n",
    "val_split = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fa5cccb31d0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maxi/.virtualenvs/py3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/maxi/.virtualenvs/py3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n",
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fa5cb236ba8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maxi/.virtualenvs/py3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/maxi/.virtualenvs/py3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 43965 samples, validate on 4885 samples\n",
      "Epoch 1/20\n",
      "43965/43965 [==============================] - 105s 2ms/step - loss: 5.1963 - weighted_categorical_accuracy: 0.0293 - val_loss: 3.9910 - val_weighted_categorical_accuracy: 0.0817\n",
      "\n",
      "Epoch 00001: saving model to ./cp-0001.ckpt\n",
      "Epoch 2/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 4.3002 - weighted_categorical_accuracy: 0.0801 - val_loss: 3.3475 - val_weighted_categorical_accuracy: 0.1713\n",
      "\n",
      "Epoch 00002: saving model to ./cp-0002.ckpt\n",
      "Epoch 3/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 3.6437 - weighted_categorical_accuracy: 0.1480 - val_loss: 2.9977 - val_weighted_categorical_accuracy: 0.2532\n",
      "\n",
      "Epoch 00003: saving model to ./cp-0003.ckpt\n",
      "Epoch 4/20\n",
      "43965/43965 [==============================] - 106s 2ms/step - loss: 3.2389 - weighted_categorical_accuracy: 0.2049 - val_loss: 2.7574 - val_weighted_categorical_accuracy: 0.3034\n",
      "\n",
      "Epoch 00004: saving model to ./cp-0004.ckpt\n",
      "Epoch 5/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 2.9754 - weighted_categorical_accuracy: 0.2513 - val_loss: 2.6050 - val_weighted_categorical_accuracy: 0.3286\n",
      "\n",
      "Epoch 00005: saving model to ./cp-0005.ckpt\n",
      "Epoch 6/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 2.7898 - weighted_categorical_accuracy: 0.2846 - val_loss: 2.4727 - val_weighted_categorical_accuracy: 0.3648\n",
      "\n",
      "Epoch 00006: saving model to ./cp-0006.ckpt\n",
      "Epoch 7/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 2.6445 - weighted_categorical_accuracy: 0.3164 - val_loss: 2.3618 - val_weighted_categorical_accuracy: 0.3939\n",
      "\n",
      "Epoch 00007: saving model to ./cp-0007.ckpt\n",
      "Epoch 8/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 2.5304 - weighted_categorical_accuracy: 0.3372 - val_loss: 2.2519 - val_weighted_categorical_accuracy: 0.4235\n",
      "\n",
      "Epoch 00008: saving model to ./cp-0008.ckpt\n",
      "Epoch 9/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 2.4365 - weighted_categorical_accuracy: 0.3609 - val_loss: 2.2163 - val_weighted_categorical_accuracy: 0.4235\n",
      "\n",
      "Epoch 00009: saving model to ./cp-0009.ckpt\n",
      "Epoch 10/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 2.3587 - weighted_categorical_accuracy: 0.3791 - val_loss: 2.1605 - val_weighted_categorical_accuracy: 0.4395\n",
      "\n",
      "Epoch 00010: saving model to ./cp-0010.ckpt\n",
      "Epoch 11/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 2.2805 - weighted_categorical_accuracy: 0.3988 - val_loss: 2.1120 - val_weighted_categorical_accuracy: 0.4518\n",
      "\n",
      "Epoch 00011: saving model to ./cp-0011.ckpt\n",
      "Epoch 12/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 2.2271 - weighted_categorical_accuracy: 0.4108 - val_loss: 2.0800 - val_weighted_categorical_accuracy: 0.4549\n",
      "\n",
      "Epoch 00012: saving model to ./cp-0012.ckpt\n",
      "Epoch 13/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 2.1708 - weighted_categorical_accuracy: 0.4251 - val_loss: 2.0216 - val_weighted_categorical_accuracy: 0.4735\n",
      "\n",
      "Epoch 00013: saving model to ./cp-0013.ckpt\n",
      "Epoch 14/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 2.1256 - weighted_categorical_accuracy: 0.4359 - val_loss: 2.0205 - val_weighted_categorical_accuracy: 0.4633\n",
      "\n",
      "Epoch 00014: saving model to ./cp-0014.ckpt\n",
      "Epoch 15/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 2.0899 - weighted_categorical_accuracy: 0.4400 - val_loss: 1.9605 - val_weighted_categorical_accuracy: 0.4809\n",
      "\n",
      "Epoch 00015: saving model to ./cp-0015.ckpt\n",
      "Epoch 16/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 2.0494 - weighted_categorical_accuracy: 0.4536 - val_loss: 1.9784 - val_weighted_categorical_accuracy: 0.4757\n",
      "\n",
      "Epoch 00016: saving model to ./cp-0016.ckpt\n",
      "Epoch 17/20\n",
      "43965/43965 [==============================] - 102s 2ms/step - loss: 2.0176 - weighted_categorical_accuracy: 0.4604 - val_loss: 1.9431 - val_weighted_categorical_accuracy: 0.4837\n",
      "\n",
      "Epoch 00017: saving model to ./cp-0017.ckpt\n",
      "Epoch 18/20\n",
      "43965/43965 [==============================] - 101s 2ms/step - loss: 1.9883 - weighted_categorical_accuracy: 0.4661 - val_loss: 1.9274 - val_weighted_categorical_accuracy: 0.4882\n",
      "\n",
      "Epoch 00018: saving model to ./cp-0018.ckpt\n",
      "Epoch 19/20\n",
      "43965/43965 [==============================] - 101s 2ms/step - loss: 1.9568 - weighted_categorical_accuracy: 0.4699 - val_loss: 1.9052 - val_weighted_categorical_accuracy: 0.4878\n",
      "\n",
      "Epoch 00019: saving model to ./cp-0019.ckpt\n",
      "Epoch 20/20\n",
      "43965/43965 [==============================] - 107s 2ms/step - loss: 1.9361 - weighted_categorical_accuracy: 0.4803 - val_loss: 1.9067 - val_weighted_categorical_accuracy: 0.4929\n",
      "\n",
      "Epoch 00020: saving model to ./cp-0020.ckpt\n",
      "Time spent: [s]: 2135\n",
      "Evaluating model...\n",
      "43965/43965 [==============================] - 20s 454us/step\n",
      "4885/4885 [==============================] - 2s 417us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5232116455119664, 1.9067255150210285, 0.4929375664116538, 2134.975222000001)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_2, eval_data_2, train_labels_2, eval_labels_2 = train_test_split(data_2, labels_2, test_size=val_split, random_state=456, stratify=np.argmax(labels_2, axis=1))\n",
    "\n",
    "tuning_step.reset_keras()\n",
    "\n",
    "my_model_2 = MyModel(hyperparams)\n",
    "my_model_2.train(train_params, train_data_2, train_labels_2, eval_data_2, eval_labels_2, labels_2_weights, checkpoints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy [%]:  52.321164551196645\n",
      "Eval accuracy [%]:  49.29375664116538\n",
      "Bias [%]:  47.678835448803355\n",
      "Variance [%]:  3.0274079100312656\n"
     ]
    }
   ],
   "source": [
    "my_model_2.print_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_model_2.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model is fitting ok, so we could still try training more epochs. But for now we will continue with the rest of the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will make predictions on dataset_3 (Text+Rating+Business.csv) to get some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3131/3131 [==============================] - 2s 722us/step\n"
     ]
    }
   ],
   "source": [
    "predictions_business_data_3 = my_model_2.model.predict(data_3, batch_size=train_params[\"BATCH_SIZE\"], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Schwartzs</th>\n",
       "      <th>Little Miss BBQ</th>\n",
       "      <th>Yama Sushi</th>\n",
       "      <th>Lux Central</th>\n",
       "      <th>Lotus of Siam</th>\n",
       "      <th>Bouchon at the Venezia Tower</th>\n",
       "      <th>Bobby Q</th>\n",
       "      <th>Pampas Churrascaria Brazilian Grille</th>\n",
       "      <th>Mesa Grill</th>\n",
       "      <th>Yardbird Southern Table &amp; Bar</th>\n",
       "      <th>Pizzeria Bianco</th>\n",
       "      <th>Pai Northern Thai Kitchen</th>\n",
       "      <th>Gordon Ramsay BurGR</th>\n",
       "      <th>Rehab Burger Therapy</th>\n",
       "      <th>Golden Nugget</th>\n",
       "      <th>The Mirage</th>\n",
       "      <th>Firefly</th>\n",
       "      <th>Bachi Burger</th>\n",
       "      <th>Bellagio Hotel</th>\n",
       "      <th>Joe's Farm Grill</th>\n",
       "      <th>Luxor Hotel and Casino Las Vegas</th>\n",
       "      <th>Cibo</th>\n",
       "      <th>Monte Carlo Hotel And Casino</th>\n",
       "      <th>Rio All Suites Hotel &amp; Casino</th>\n",
       "      <th>Gordon Ramsay Pub &amp; Grill</th>\n",
       "      <th>Hard Rock Hotel &amp; Casino</th>\n",
       "      <th>Marquee Nightclub &amp; Dayclub</th>\n",
       "      <th>ARIA Resort &amp; Casino</th>\n",
       "      <th>El Dorado Cantina</th>\n",
       "      <th>Giada</th>\n",
       "      <th>Carson Kitchen</th>\n",
       "      <th>Wynn Las Vegas</th>\n",
       "      <th>Spice Market Buffet</th>\n",
       "      <th>Studio B Buffet</th>\n",
       "      <th>The Peppermill Restaurant &amp; Fireside Lounge</th>\n",
       "      <th>Excalibur Hotel</th>\n",
       "      <th>Hash House A Go Go</th>\n",
       "      <th>SkinnyFATS</th>\n",
       "      <th>The Venetian Las Vegas</th>\n",
       "      <th>HEXX kitchen + bar</th>\n",
       "      <th>The Buffet</th>\n",
       "      <th>OTHERS</th>\n",
       "      <th>SLS Las Vegas, A Tribute Portfolio Resort</th>\n",
       "      <th>Shake Shack</th>\n",
       "      <th>Wicked Spoon</th>\n",
       "      <th>SUSHISAMBA - Las Vegas</th>\n",
       "      <th>Rollin Smoke Barbeque</th>\n",
       "      <th>XS Nightclub</th>\n",
       "      <th>Secret Pizza</th>\n",
       "      <th>Vdara Hotel</th>\n",
       "      <th>Serendipity 3</th>\n",
       "      <th>The Palazzo Las Vegas</th>\n",
       "      <th>Treasure Island</th>\n",
       "      <th>Stratosphere</th>\n",
       "      <th>The Oyster Bar</th>\n",
       "      <th>TAO Nightclub</th>\n",
       "      <th>Tom Colicchio's Craftsteak</th>\n",
       "      <th>Tacos El Gordo</th>\n",
       "      <th>The Arrogant Butcher</th>\n",
       "      <th>The Buffet at ARIA</th>\n",
       "      <th>The Buffet at Bellagio</th>\n",
       "      <th>The Cosmopolitan of Las Vegas</th>\n",
       "      <th>The LINQ Hotel &amp; Casino</th>\n",
       "      <th>Planet Hollywood Las Vegas Resort &amp; Casino</th>\n",
       "      <th>Circus Circus Las Vegas Hotel and Casino</th>\n",
       "      <th>Pizza Rock</th>\n",
       "      <th>Four Peaks Brewing</th>\n",
       "      <th>High Roller</th>\n",
       "      <th>Hakkasan Nightclub</th>\n",
       "      <th>Guy Fieri's Vegas Kitchen &amp; Bar</th>\n",
       "      <th>Grand Lux Cafe</th>\n",
       "      <th>Gordon Ramsay Steak</th>\n",
       "      <th>Gangnam Asian BBQ Dining</th>\n",
       "      <th>Flamingo Las Vegas Hotel &amp; Casino</th>\n",
       "      <th>Joes Seafood Prime Steak &amp; Stone Crab</th>\n",
       "      <th>Encore</th>\n",
       "      <th>Ellis Island Hotel, Casino &amp; Brewery</th>\n",
       "      <th>Egg &amp; I</th>\n",
       "      <th>Echo &amp; Rig</th>\n",
       "      <th>Eat.</th>\n",
       "      <th>Earl of Sandwich</th>\n",
       "      <th>Holsteins Shakes &amp; Buns</th>\n",
       "      <th>KA by Cirque Du Soleil</th>\n",
       "      <th>Phoenix Sky Harbor International Airport</th>\n",
       "      <th>Monta Ramen</th>\n",
       "      <th>Pho Kim Long</th>\n",
       "      <th>Paris Las Vegas Hotel &amp; Casino</th>\n",
       "      <th>Burger Bar</th>\n",
       "      <th>Olives</th>\n",
       "      <th>Cirque du Soleil - The Beatles LOVE</th>\n",
       "      <th>Mr Mamas</th>\n",
       "      <th>Mon Ami Gabi</th>\n",
       "      <th>La Santisima</th>\n",
       "      <th>Bacchanal Buffet</th>\n",
       "      <th>McCarran International Airport</th>\n",
       "      <th>Mandalay Bay Resort &amp; Casino</th>\n",
       "      <th>MGM Grand Hotel</th>\n",
       "      <th>Caesars Palace Las Vegas Hotel &amp; Casino</th>\n",
       "      <th>Le Village Buffet</th>\n",
       "      <th>New York New York Hotel &amp; Casino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.713043</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.589474</td>\n",
       "      <td>0.577465</td>\n",
       "      <td>0.564885</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.536082</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.496124</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>0.455285</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.416107</td>\n",
       "      <td>0.416000</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>0.403361</td>\n",
       "      <td>0.323810</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.424658</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.581081</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.388060</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.364486</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.407895</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.269663</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Schwartzs  Little Miss BBQ  Yama Sushi  Lux Central  \\\n",
       "f1-score     0.912281         0.817204    0.792453     0.747475   \n",
       "precision    0.928571         0.760000    0.750000     0.755102   \n",
       "recall       0.896552         0.883721    0.840000     0.740000   \n",
       "support     58.000000        43.000000   50.000000    50.000000   \n",
       "\n",
       "           Lotus of Siam  Bouchon at the Venezia Tower    Bobby Q  \\\n",
       "f1-score        0.729167                      0.723404   0.718447   \n",
       "precision       0.921053                      0.850000   0.902439   \n",
       "recall          0.603448                      0.629630   0.596774   \n",
       "support       116.000000                    108.000000  62.000000   \n",
       "\n",
       "           Pampas Churrascaria Brazilian Grille  Mesa Grill  \\\n",
       "f1-score                               0.713043    0.692308   \n",
       "precision                              0.872340    0.833333   \n",
       "recall                                 0.602941    0.592105   \n",
       "support                               68.000000   76.000000   \n",
       "\n",
       "           Yardbird Southern Table & Bar  Pizzeria Bianco  \\\n",
       "f1-score                        0.682540         0.666667   \n",
       "precision                       0.826923         0.723404   \n",
       "recall                          0.581081         0.618182   \n",
       "support                        74.000000        55.000000   \n",
       "\n",
       "           Pai Northern Thai Kitchen  Gordon Ramsay BurGR  \\\n",
       "f1-score                    0.659091             0.611111   \n",
       "precision                   0.674419             0.733333   \n",
       "recall                      0.644444             0.523810   \n",
       "support                    45.000000           147.000000   \n",
       "\n",
       "           Rehab Burger Therapy  Golden Nugget  The Mirage    Firefly  \\\n",
       "f1-score               0.605263       0.595745    0.595238   0.589474   \n",
       "precision              0.500000       0.622222    0.862069   0.538462   \n",
       "recall                 0.766667       0.571429    0.454545   0.651163   \n",
       "support               60.000000      49.000000   55.000000  43.000000   \n",
       "\n",
       "           Bachi Burger  Bellagio Hotel  Joe's Farm Grill  \\\n",
       "f1-score       0.577465        0.564885          0.559140   \n",
       "precision      0.694915        0.685185          0.742857   \n",
       "recall         0.493976        0.480519          0.448276   \n",
       "support       83.000000       77.000000         58.000000   \n",
       "\n",
       "           Luxor Hotel and Casino Las Vegas       Cibo  \\\n",
       "f1-score                           0.558824   0.547945   \n",
       "precision                          0.808511   0.666667   \n",
       "recall                             0.426966   0.465116   \n",
       "support                           89.000000  43.000000   \n",
       "\n",
       "           Monte Carlo Hotel And Casino  Rio All Suites Hotel & Casino  \\\n",
       "f1-score                       0.536082                       0.535211   \n",
       "precision                      0.866667                       0.826087   \n",
       "recall                         0.388060                       0.395833   \n",
       "support                       67.000000                      48.000000   \n",
       "\n",
       "           Gordon Ramsay Pub & Grill  Hard Rock Hotel & Casino  \\\n",
       "f1-score                    0.530612                  0.527273   \n",
       "precision                   0.812500                  0.674419   \n",
       "recall                      0.393939                  0.432836   \n",
       "support                    99.000000                 67.000000   \n",
       "\n",
       "           Marquee Nightclub & Dayclub  ARIA Resort & Casino  \\\n",
       "f1-score                      0.515152              0.509804   \n",
       "precision                     0.894737              0.847826   \n",
       "recall                        0.361702              0.364486   \n",
       "support                      47.000000            107.000000   \n",
       "\n",
       "           El Dorado Cantina      Giada  Carson Kitchen  Wynn Las Vegas  \\\n",
       "f1-score            0.507692   0.496124        0.493151        0.464000   \n",
       "precision           0.412500   0.680851        0.750000        0.500000   \n",
       "recall              0.660000   0.390244        0.367347        0.432836   \n",
       "support            50.000000  82.000000       49.000000       67.000000   \n",
       "\n",
       "           Spice Market Buffet  Studio B Buffet  \\\n",
       "f1-score              0.455285         0.450704   \n",
       "precision             0.368421         1.000000   \n",
       "recall                0.595745         0.290909   \n",
       "support              47.000000        55.000000   \n",
       "\n",
       "           The Peppermill Restaurant & Fireside Lounge  Excalibur Hotel  \\\n",
       "f1-score                                      0.431034         0.416107   \n",
       "precision                                     0.555556         0.424658   \n",
       "recall                                        0.352113         0.407895   \n",
       "support                                      71.000000        76.000000   \n",
       "\n",
       "           Hash House A Go Go  SkinnyFATS  The Venetian Las Vegas  \\\n",
       "f1-score             0.416000    0.406780                0.403361   \n",
       "precision            0.838710    0.393443                0.800000   \n",
       "recall               0.276596    0.421053                0.269663   \n",
       "support             94.000000   57.000000               89.000000   \n",
       "\n",
       "           HEXX kitchen + bar  The Buffet      OTHERS  \\\n",
       "f1-score             0.323810    0.318182    0.019672   \n",
       "precision            0.333333    0.700000    0.272727   \n",
       "recall               0.314815    0.205882    0.010204   \n",
       "support             54.000000  102.000000  294.000000   \n",
       "\n",
       "           SLS Las Vegas, A Tribute Portfolio Resort  Shake Shack  \\\n",
       "f1-score                                         0.0          0.0   \n",
       "precision                                        0.0          0.0   \n",
       "recall                                           0.0          0.0   \n",
       "support                                          0.0          0.0   \n",
       "\n",
       "           Wicked Spoon  SUSHISAMBA - Las Vegas  Rollin Smoke Barbeque  \\\n",
       "f1-score            0.0                     0.0                    0.0   \n",
       "precision           0.0                     0.0                    0.0   \n",
       "recall              0.0                     0.0                    0.0   \n",
       "support             0.0                     0.0                    0.0   \n",
       "\n",
       "           XS Nightclub  Secret Pizza  Vdara Hotel  Serendipity 3  \\\n",
       "f1-score            0.0           0.0          0.0            0.0   \n",
       "precision           0.0           0.0          0.0            0.0   \n",
       "recall              0.0           0.0          0.0            0.0   \n",
       "support             0.0           0.0          0.0            0.0   \n",
       "\n",
       "           The Palazzo Las Vegas  Treasure Island  Stratosphere  \\\n",
       "f1-score                     0.0              0.0           0.0   \n",
       "precision                    0.0              0.0           0.0   \n",
       "recall                       0.0              0.0           0.0   \n",
       "support                      0.0              0.0           0.0   \n",
       "\n",
       "           The Oyster Bar  TAO Nightclub  Tom Colicchio's Craftsteak  \\\n",
       "f1-score              0.0            0.0                         0.0   \n",
       "precision             0.0            0.0                         0.0   \n",
       "recall                0.0            0.0                         0.0   \n",
       "support               0.0            0.0                         0.0   \n",
       "\n",
       "           Tacos El Gordo  The Arrogant Butcher  The Buffet at ARIA  \\\n",
       "f1-score              0.0                   0.0                 0.0   \n",
       "precision             0.0                   0.0                 0.0   \n",
       "recall                0.0                   0.0                 0.0   \n",
       "support               0.0                   0.0                 0.0   \n",
       "\n",
       "           The Buffet at Bellagio  The Cosmopolitan of Las Vegas  \\\n",
       "f1-score                      0.0                            0.0   \n",
       "precision                     0.0                            0.0   \n",
       "recall                        0.0                            0.0   \n",
       "support                       0.0                            0.0   \n",
       "\n",
       "           The LINQ Hotel & Casino  \\\n",
       "f1-score                       0.0   \n",
       "precision                      0.0   \n",
       "recall                         0.0   \n",
       "support                        0.0   \n",
       "\n",
       "           Planet Hollywood Las Vegas Resort & Casino  \\\n",
       "f1-score                                          0.0   \n",
       "precision                                         0.0   \n",
       "recall                                            0.0   \n",
       "support                                           0.0   \n",
       "\n",
       "           Circus Circus Las Vegas Hotel and Casino  Pizza Rock  \\\n",
       "f1-score                                        0.0         0.0   \n",
       "precision                                       0.0         0.0   \n",
       "recall                                          0.0         0.0   \n",
       "support                                         0.0         0.0   \n",
       "\n",
       "           Four Peaks Brewing  High Roller  Hakkasan Nightclub  \\\n",
       "f1-score                  0.0          0.0                 0.0   \n",
       "precision                 0.0          0.0                 0.0   \n",
       "recall                    0.0          0.0                 0.0   \n",
       "support                   0.0          0.0                 0.0   \n",
       "\n",
       "           Guy Fieri's Vegas Kitchen & Bar  Grand Lux Cafe  \\\n",
       "f1-score                               0.0             0.0   \n",
       "precision                              0.0             0.0   \n",
       "recall                                 0.0             0.0   \n",
       "support                                0.0             0.0   \n",
       "\n",
       "           Gordon Ramsay Steak  Gangnam Asian BBQ Dining  \\\n",
       "f1-score                   0.0                       0.0   \n",
       "precision                  0.0                       0.0   \n",
       "recall                     0.0                       0.0   \n",
       "support                    0.0                       0.0   \n",
       "\n",
       "           Flamingo Las Vegas Hotel & Casino  \\\n",
       "f1-score                                 0.0   \n",
       "precision                                0.0   \n",
       "recall                                   0.0   \n",
       "support                                  0.0   \n",
       "\n",
       "           Joes Seafood Prime Steak & Stone Crab  Encore  \\\n",
       "f1-score                                     0.0     0.0   \n",
       "precision                                    0.0     0.0   \n",
       "recall                                       0.0     0.0   \n",
       "support                                      0.0     0.0   \n",
       "\n",
       "           Ellis Island Hotel, Casino & Brewery  Egg & I  Echo & Rig  Eat.  \\\n",
       "f1-score                                    0.0      0.0         0.0   0.0   \n",
       "precision                                   0.0      0.0         0.0   0.0   \n",
       "recall                                      0.0      0.0         0.0   0.0   \n",
       "support                                     0.0      0.0         0.0   0.0   \n",
       "\n",
       "           Earl of Sandwich  Holsteins Shakes & Buns  KA by Cirque Du Soleil  \\\n",
       "f1-score                0.0                      0.0                     0.0   \n",
       "precision               0.0                      0.0                     0.0   \n",
       "recall                  0.0                      0.0                     0.0   \n",
       "support                 0.0                      0.0                     0.0   \n",
       "\n",
       "           Phoenix Sky Harbor International Airport  Monta Ramen  \\\n",
       "f1-score                                        0.0          0.0   \n",
       "precision                                       0.0          0.0   \n",
       "recall                                          0.0          0.0   \n",
       "support                                         0.0          0.0   \n",
       "\n",
       "           Pho Kim Long  Paris Las Vegas Hotel & Casino  Burger Bar  Olives  \\\n",
       "f1-score            0.0                             0.0         0.0     0.0   \n",
       "precision           0.0                             0.0         0.0     0.0   \n",
       "recall              0.0                             0.0         0.0     0.0   \n",
       "support             0.0                             0.0         0.0     0.0   \n",
       "\n",
       "           Cirque du Soleil - The Beatles LOVE  Mr Mamas  Mon Ami Gabi  \\\n",
       "f1-score                                   0.0       0.0           0.0   \n",
       "precision                                  0.0       0.0           0.0   \n",
       "recall                                     0.0       0.0           0.0   \n",
       "support                                    0.0       0.0           0.0   \n",
       "\n",
       "           La Santisima  Bacchanal Buffet  McCarran International Airport  \\\n",
       "f1-score            0.0               0.0                             0.0   \n",
       "precision           0.0               0.0                             0.0   \n",
       "recall              0.0               0.0                             0.0   \n",
       "support             0.0               0.0                             0.0   \n",
       "\n",
       "           Mandalay Bay Resort & Casino  MGM Grand Hotel  \\\n",
       "f1-score                            0.0              0.0   \n",
       "precision                           0.0              0.0   \n",
       "recall                              0.0              0.0   \n",
       "support                             0.0              0.0   \n",
       "\n",
       "           Caesars Palace Las Vegas Hotel & Casino  Le Village Buffet  \\\n",
       "f1-score                                       0.0                0.0   \n",
       "precision                                      0.0                0.0   \n",
       "recall                                         0.0                0.0   \n",
       "support                                        0.0                0.0   \n",
       "\n",
       "           New York New York Hotel & Casino  \n",
       "f1-score                                0.0  \n",
       "precision                               0.0  \n",
       "recall                                  0.0  \n",
       "support                                 0.0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(y_true=[text_and_business_hashtable.get(elem) for elem in business_3], y_pred=predictions_business_data_3.argmax(axis=1), labels=range(0,labels_2.shape[1]), target_names=real_labels_3_names, output_dict=True)\n",
    "df_report = pd.DataFrame(report)\n",
    "metrics_cols = ['micro avg', 'macro avg', 'weighted avg']\n",
    "df_report_by_review = df_report.drop(columns=metrics_cols, inplace=False).sort_values(by=\"f1-score\", axis=1, ascending=False)\n",
    "\n",
    "df_report.to_csv(\"report_model_2_by_review.csv\", encoding = 'utf-8')\n",
    "df_report_by_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model classifies better Schwartz's reviews than the The Buffet reviews. So we could use the first X columns of this table to, answering one of the challenge's tasks, provide value to some of the companies in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>macro avg</th>\n",
       "      <th>micro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.231834</td>\n",
       "      <td>0.446503</td>\n",
       "      <td>0.515073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.293111</td>\n",
       "      <td>0.446503</td>\n",
       "      <td>0.687406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.206371</td>\n",
       "      <td>0.446503</td>\n",
       "      <td>0.446503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>3131.000000</td>\n",
       "      <td>3131.000000</td>\n",
       "      <td>3131.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             macro avg    micro avg  weighted avg\n",
       "f1-score      0.231834     0.446503      0.515073\n",
       "precision     0.293111     0.446503      0.687406\n",
       "recall        0.206371     0.446503      0.446503\n",
       "support    3131.000000  3131.000000   3131.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_cols = df_report.columns.values.tolist()\n",
    "drop_cols = (set(all_cols)-set(metrics_cols))\n",
    "df_report_by_metrics = df_report.drop(columns=drop_cols, inplace=False)\n",
    "display(df_report_by_metrics)\n",
    "df_report.to_csv(\"report_model_2_by_metrics.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will make the inferences of the comapies of the texts from MyExperiences.csv. We will be reading this file in chunks, as it is too large (and unnecessary) to open it completely. But we can increase the batch_size for the inference process, as it uses less memory than the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 39s 391us/step\n",
      "100000/100000 [==============================] - 39s 393us/step\n",
      "100000/100000 [==============================] - 40s 400us/step\n",
      " 69632/100000 [===================>..........] - ETA: 12s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-235863b2155a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mchunk_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BATCH_SIZE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"business_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbusiness_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./MyExperiences_business.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.virtualenvs/py3/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chunksize = 10 ** 5\n",
    "business_ids = np.array(sorted(text_and_business_hashtable, key=text_and_business_hashtable.get))\n",
    "for chunk in pd.read_csv(\"MyExperiences.csv\", usecols=[\"review_id\",\"text\"], chunksize=chunksize):\n",
    "    texts = chunk[\"text\"].values\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    chunk_predictions = my_model_2.model.predict(data, batch_size=2*train_params[\"BATCH_SIZE\"], verbose=1)\n",
    "    chunk[\"business_id\"] = business_ids[np.argmax(chunk_predictions, axis=1)]\n",
    "    chunk.to_csv(\"./MyExperiences_business.csv\", mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I stopped the last cell just because it takes too much time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
